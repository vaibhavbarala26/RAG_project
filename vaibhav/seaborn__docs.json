[
{"chunk_id": "chunk_0", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "An introduction to seaborn#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "An introduction to seaborn#", "content": "An introduction to seaborn# Seaborn is a library for making statistical graphics in Python. It builds on top of matplotlib and integrates closely with pandas data structures. Seaborn helps you explore and understand your data. Its plotting functions operate on dataframes and arrays containing whole datasets and internally perform the necessary semantic mapping and statistical aggregation to produce informative plots. Its dataset-oriented, declarative API lets you focus on what the different elements of your plots mean, rather than on the details of how to draw them. Here’s an example of what seaborn can do: # Import seaborn import seaborn as sns # Apply the default theme sns.set_theme() # Load an example dataset tips = sns.load_dataset(\"tips\") # Create a visualization sns.relplot( data=tips, x=\"total_bill\", y=\"tip\", col=\"time\", hue=\"smoker\", style=\"smoker\", size=\"size\", )", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_1", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "A high-level API for statistical graphics#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "A high-level API for statistical graphics#", "content": "A high-level API for statistical graphics# There is no universally best way to visualize data. Different questions are best answered by different plots. Seaborn makes it easy to switch between different visual representations by using a consistent dataset-oriented API. The function relplot() is named that way because it is designed to visualize many different statistical relationships. While scatter plots are often effective, relationships where one variable represents a measure of time are better represented by a line. The relplot() function has a convenient kind parameter that lets you easily switch to this alternate representation: dots = sns.load_dataset(\"dots\") sns.relplot( data=dots, kind=\"line\", x=\"time\", y=\"firing_rate\", col=\"align\", hue=\"choice\", size=\"coherence\", style=\"choice\", facet_kws=dict(sharex=False), )", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_2", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "Statistical estimation#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Statistical estimation#", "content": "Statistical estimation# Often, we are interested in the average value of one variable as a function of other variables. Many seaborn functions will automatically perform the statistical estimation that is necessary to answer these questions: fmri = sns.load_dataset(\"fmri\") sns.relplot( data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", col=\"region\", hue=\"event\", style=\"event\", ) When statistical values are estimated, seaborn will use bootstrapping to compute confidence intervals and draw error bars representing the uncertainty of the estimate. Statistical estimation in seaborn goes beyond descriptive statistics. For example, it is possible to enhance a scatterplot by including a linear regression model (and its uncertainty) using lmplot(): sns.lmplot(data=tips, x=\"total_bill\", y=\"tip\", col=\"time\", hue=\"smoker\")", "prev_chunk_id": "chunk_1", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_3", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "Distributional representations#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Distributional representations#", "content": "Distributional representations# Statistical analyses require knowledge about the distribution of variables in your dataset. The seaborn function displot() supports several approaches to visualizing distributions. These include classic techniques like histograms and computationally-intensive approaches like kernel density estimation: sns.displot(data=tips, x=\"total_bill\", col=\"time\", kde=True) Seaborn also tries to promote techniques that are powerful but less familiar, such as calculating and plotting the empirical cumulative distribution function of the data: sns.displot(data=tips, kind=\"ecdf\", x=\"total_bill\", col=\"time\", hue=\"smoker\", rug=True)", "prev_chunk_id": "chunk_2", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_4", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "Plots for categorical data#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Plots for categorical data#", "content": "Plots for categorical data# Several specialized plot types in seaborn are oriented towards visualizing categorical data. They can be accessed through catplot(). These plots offer different levels of granularity. At the finest level, you may wish to see every observation by drawing a “swarm” plot: a scatter plot that adjusts the positions of the points along the categorical axis so that they don’t overlap: sns.catplot(data=tips, kind=\"swarm\", x=\"day\", y=\"total_bill\", hue=\"smoker\") Alternately, you could use kernel density estimation to represent the underlying distribution that the points are sampled from: sns.catplot(data=tips, kind=\"violin\", x=\"day\", y=\"total_bill\", hue=\"smoker\", split=True) Or you could show only the mean value and its confidence interval within each nested category: sns.catplot(data=tips, kind=\"bar\", x=\"day\", y=\"total_bill\", hue=\"smoker\")", "prev_chunk_id": "chunk_3", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_5", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "Multivariate views on complex datasets#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Multivariate views on complex datasets#", "content": "Multivariate views on complex datasets# Some seaborn functions combine multiple kinds of plots to quickly give informative summaries of a dataset. One, jointplot(), focuses on a single relationship. It plots the joint distribution between two variables along with each variable’s marginal distribution: penguins = sns.load_dataset(\"penguins\") sns.jointplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", hue=\"species\") The other, pairplot(), takes a broader view: it shows joint and marginal distributions for all pairwise relationships and for each variable, respectively: sns.pairplot(data=penguins, hue=\"species\")", "prev_chunk_id": "chunk_4", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_6", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "Lower-level tools for building figures#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Lower-level tools for building figures#", "content": "Lower-level tools for building figures# These tools work by combining axes-level plotting functions with objects that manage the layout of the figure, linking the structure of a dataset to a grid of axes. Both elements are part of the public API, and you can use them directly to create complex figures with only a few more lines of code: g = sns.PairGrid(penguins, hue=\"species\", corner=True) g.map_lower(sns.kdeplot, hue=None, levels=5, color=\".2\") g.map_lower(sns.scatterplot, marker=\"+\") g.map_diag(sns.histplot, element=\"step\", linewidth=0, kde=True) g.add_legend(frameon=True) g.legend.set_bbox_to_anchor((.61, .6))", "prev_chunk_id": "chunk_5", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_7", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "Opinionated defaults and flexible customization#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Opinionated defaults and flexible customization#", "content": "Opinionated defaults and flexible customization# Seaborn creates complete graphics with a single function call: when possible, its functions will automatically add informative axis labels and legends that explain the semantic mappings in the plot. In many cases, seaborn will also choose default values for its parameters based on characteristics of the data. For example, the color mappings that we have seen so far used distinct hues (blue, orange, and sometimes green) to represent different levels of the categorical variables assigned to hue. When mapping a numeric variable, some functions will switch to a continuous gradient: sns.relplot( data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"body_mass_g\" ) When you’re ready to share or publish your work, you’ll probably want to polish the figure beyond what the defaults achieve. Seaborn allows for several levels of customization. It defines multiple built-in themes that apply to all figures, its functions have standardized parameters that can modify the semantic mappings for each plot, and additional keyword arguments are passed down to the underlying matplotlib artists, allowing even more control. Once you’ve created a plot, its properties can be modified through both the seaborn API and by dropping down to the matplotlib layer for fine-grained tweaking: sns.set_theme(style=\"ticks\", font_scale=1.25) g = sns.relplot( data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"body_mass_g\", palette=\"crest\", marker=\"x\", s=100, ) g.set_axis_labels(\"Bill length (mm)\", \"Bill depth (mm)\", labelpad=10) g.legend.set_title(\"Body mass (g)\") g.figure.set_size_inches(6.5, 4.5) g.ax.margins(.15) g.despine(trim=True)", "prev_chunk_id": "chunk_6", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_8", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "Relationship to matplotlib#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Relationship to matplotlib#", "content": "Relationship to matplotlib# Seaborn’s integration with matplotlib allows you to use it across the many environments that matplotlib supports, including exploratory analysis in notebooks, real-time interaction in GUI applications, and archival output in a number of raster and vector formats. While you can be productive using only seaborn functions, full customization of your graphics will require some knowledge of matplotlib’s concepts and API. One aspect of the learning curve for new users of seaborn will be knowing when dropping down to the matplotlib layer is necessary to achieve a particular customization. On the other hand, users coming from matplotlib will find that much of their knowledge transfers. Matplotlib has a comprehensive and powerful API; just about any attribute of the figure can be changed to your liking. A combination of seaborn’s high-level interface and matplotlib’s deep customizability will allow you both to quickly explore your data and to create graphics that can be tailored into a publication quality final product.", "prev_chunk_id": "chunk_7", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_9", "url": "https://seaborn.pydata.org/tutorial/introduction.html", "title": "Next steps#", "page_title": "An introduction to seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Next steps#", "content": "Next steps# You have a few options for where to go next. You might first want to learn how to install seaborn. Once that’s done, you can browse the example gallery to get a broader sense for what kind of graphics seaborn can produce. Or you can read through the rest of the user guide and tutorial for a deeper discussion of the different tools and what they are designed to accomplish. If you have a specific plot in mind and want to know how to make it, you could check out the API reference, which documents each function’s parameters and shows many examples to illustrate usage.", "prev_chunk_id": "chunk_8", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_10", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Overview of seaborn plotting functions#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Overview of seaborn plotting functions#", "content": "Overview of seaborn plotting functions# Most of your interactions with seaborn will happen through a set of plotting functions. Later chapters in the tutorial will explore the specific features offered by each function. This chapter will introduce, at a high-level, the different kinds of functions that you will encounter.", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_11", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Similar functions for similar tasks#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Similar functions for similar tasks#", "content": "Similar functions for similar tasks# The seaborn namespace is flat; all of the functionality is accessible at the top level. But the code itself is hierarchically structured, with modules of functions that achieve similar visualization goals through different means. Most of the docs are structured around these modules: you’ll encounter names like “relational”, “distributional”, and “categorical”. For example, the distributions module defines functions that specialize in representing the distribution of datapoints. This includes familiar methods like the histogram: penguins = sns.load_dataset(\"penguins\") sns.histplot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", multiple=\"stack\")", "prev_chunk_id": "chunk_10", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_12", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Figure-level vs. axes-level functions#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Figure-level vs. axes-level functions#", "content": "Figure-level vs. axes-level functions# In addition to the different modules, there is a cross-cutting classification of seaborn functions as “axes-level” or “figure-level”. The examples above are axes-level functions. They plot data onto a single matplotlib.pyplot.Axes object, which is the return value of the function. In contrast, figure-level functions interface with matplotlib through a seaborn object, usually a FacetGrid, that manages the figure. Each module has a single figure-level function, which offers a unitary interface to its various axes-level functions. The organization looks a bit like this: For example, displot() is the figure-level function for the distributions module. Its default behavior is to draw a histogram, using the same code as histplot() behind the scenes: sns.displot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", multiple=\"stack\") To draw a kernel density plot instead, using the same code as kdeplot(), select it using the kind parameter: sns.displot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", multiple=\"stack\", kind=\"kde\") You’ll notice that the figure-level plots look mostly like their axes-level counterparts, but there are a few differences. Notably, the legend is placed outside the plot. They also have a slightly different shape (more on that shortly). The most useful feature offered by the figure-level functions is that they can easily create figures with multiple subplots. For example, instead of stacking the three distributions for each species of penguins in the same axes, we can “facet” them by plotting each distribution across the columns of the figure: sns.displot(data=penguins, x=\"flipper_length_mm\", hue=\"species\", col=\"species\") The figure-level functions wrap their axes-level counterparts and pass the kind-specific keyword arguments (such as the bin size for a histogram) down to the underlying function. That means they are no less flexible, but there is a downside: the kind-specific parameters don’t appear in the function signature or docstrings. Some of their features might be less discoverable, and you may need to look at two different pages", "prev_chunk_id": "chunk_11", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_13", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Figure-level vs. axes-level functions#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Figure-level vs. axes-level functions#", "content": "of the documentation before understanding how to achieve a specific goal.", "prev_chunk_id": "chunk_12", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_14", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Axes-level functions make self-contained plots#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Axes-level functions make self-contained plots#", "content": "Axes-level functions make self-contained plots# The axes-level functions are written to act like drop-in replacements for matplotlib functions. While they add axis labels and legends automatically, they don’t modify anything beyond the axes that they are drawn into. That means they can be composed into arbitrarily-complex matplotlib figures with predictable results. The axes-level functions call matplotlib.pyplot.gca() internally, which hooks into the matplotlib state-machine interface so that they draw their plots on the “currently-active” axes. But they additionally accept an ax= argument, which integrates with the object-oriented interface and lets you specify exactly where each plot should go: f, axs = plt.subplots(1, 2, figsize=(8, 4), gridspec_kw=dict(width_ratios=[4, 3])) sns.scatterplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", hue=\"species\", ax=axs[0]) sns.histplot(data=penguins, x=\"species\", hue=\"species\", shrink=.8, alpha=.8, legend=False, ax=axs[1]) f.tight_layout()", "prev_chunk_id": "chunk_13", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_15", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Figure-level functions own their figure#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Figure-level functions own their figure#", "content": "Figure-level functions own their figure# In contrast, figure-level functions cannot (easily) be composed with other plots. By design, they “own” their own figure, including its initialization, so there’s no notion of using a figure-level function to draw a plot onto an existing axes. This constraint allows the figure-level functions to implement features such as putting the legend outside of the plot. Nevertheless, it is possible to go beyond what the figure-level functions offer by accessing the matplotlib axes on the object that they return and adding other elements to the plot that way: tips = sns.load_dataset(\"tips\") g = sns.relplot(data=tips, x=\"total_bill\", y=\"tip\") g.ax.axline(xy1=(10, 2), slope=.2, color=\"b\", dashes=(5, 2))", "prev_chunk_id": "chunk_14", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_16", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Customizing plots from a figure-level function#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Customizing plots from a figure-level function#", "content": "Customizing plots from a figure-level function# The figure-level functions return a FacetGrid instance, which has a few methods for customizing attributes of the plot in a way that is “smart” about the subplot organization. For example, you can change the labels on the external axes using a single line of code: g = sns.relplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", col=\"sex\") g.set_axis_labels(\"Flipper length (mm)\", \"Bill length (mm)\") While convenient, this does add a bit of extra complexity, as you need to remember that this method is not part of the matplotlib API and exists only when using a figure-level function.", "prev_chunk_id": "chunk_15", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_17", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Specifying figure sizes#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Specifying figure sizes#", "content": "Specifying figure sizes# To increase or decrease the size of a matplotlib plot, you set the width and height of the entire figure, either in the global rcParams, while setting up the plot (e.g. with the figsize parameter of matplotlib.pyplot.subplots()), or by calling a method on the figure object (e.g. matplotlib.Figure.set_size_inches()). When using an axes-level function in seaborn, the same rules apply: the size of the plot is determined by the size of the figure it is part of and the axes layout in that figure. When using a figure-level function, there are several key differences. First, the functions themselves have parameters to control the figure size (although these are actually parameters of the underlying FacetGrid that manages the figure). Second, these parameters, height and aspect, parameterize the size slightly differently than the width, height parameterization in matplotlib (using the seaborn parameters, width = height * aspect). Most importantly, the parameters correspond to the size of each subplot, rather than the size of the overall figure. To illustrate the difference between these approaches, here is the default output of matplotlib.pyplot.subplots() with one subplot: f, ax = plt.subplots() A figure with multiple columns will have the same overall size, but the axes will be squeezed horizontally to fit in the space: f, ax = plt.subplots(1, 2, sharey=True) In contrast, a plot created by a figure-level function will be square. To demonstrate that, let’s set up an empty plot by using FacetGrid directly. This happens behind the scenes in functions like relplot(), displot(), or catplot(): g = sns.FacetGrid(penguins) When additional columns are added, the figure itself will become wider, so that its subplots have the same size and shape: g = sns.FacetGrid(penguins, col=\"sex\") And you can adjust the size and shape of each subplot without accounting for the total number of rows", "prev_chunk_id": "chunk_16", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_18", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Specifying figure sizes#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Specifying figure sizes#", "content": "and columns in the figure: g = sns.FacetGrid(penguins, col=\"sex\", height=3.5, aspect=.75) The upshot is that you can assign faceting variables without stopping to think about how you’ll need to adjust the total figure size. A downside is that, when you do want to change the figure size, you’ll need to remember that things work a bit differently than they do in matplotlib.", "prev_chunk_id": "chunk_17", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_19", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Relative merits of figure-level functions#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Relative merits of figure-level functions#", "content": "Relative merits of figure-level functions# Here is a summary of the pros and cons that we have discussed above: Advantages | Drawbacks Easy faceting by data variables | Many parameters not in function signature Legend outside of plot by default | Cannot be part of a larger matplotlib figure Easy figure-level customization | Different API from matplotlib Different figure size parameterization | Different figure size parameterization On balance, the figure-level functions add some additional complexity that can make things more confusing for beginners, but their distinct features give them additional power. The tutorial documentation mostly uses the figure-level functions, because they produce slightly cleaner plots, and we generally recommend their use for most applications. The one situation where they are not a good choice is when you need to make a complex, standalone figure that composes multiple different plot kinds. At this point, it’s recommended to set up the figure using matplotlib directly and to fill in the individual components using axes-level functions.", "prev_chunk_id": "chunk_18", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_20", "url": "https://seaborn.pydata.org/tutorial/function_overview.html", "title": "Combining multiple views on the data#", "page_title": "Overview of seaborn plotting functions — seaborn 0.13.2 documentation", "breadcrumbs": "Combining multiple views on the data#", "content": "Combining multiple views on the data# Two important plotting functions in seaborn don’t fit cleanly into the classification scheme discussed above. These functions, jointplot() and pairplot(), employ multiple kinds of plots from different modules to represent multiple aspects of a dataset in a single figure. Both plots are figure-level functions and create figures with multiple subplots by default. But they use different objects to manage the figure: JointGrid and PairGrid, respectively. jointplot() plots the relationship or joint distribution of two variables while adding marginal axes that show the univariate distribution of each one separately: sns.jointplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", hue=\"species\") pairplot() is similar — it combines joint and marginal views — but rather than focusing on a single relationship, it visualizes every pairwise combination of variables simultaneously: sns.pairplot(data=penguins, hue=\"species\") Behind the scenes, these functions are using axes-level functions that you have already met (scatterplot() and kdeplot()), and they also have a kind parameter that lets you quickly swap in a different representation: sns.jointplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", hue=\"species\", kind=\"hist\")", "prev_chunk_id": "chunk_19", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_21", "url": "https://seaborn.pydata.org/tutorial/data_structure.html", "title": "Data structures accepted by seaborn#", "page_title": "Data structures accepted by seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Data structures accepted by seaborn#", "content": "Data structures accepted by seaborn# As a data visualization library, seaborn requires that you provide it with data. This chapter explains the various ways to accomplish that task. Seaborn supports several different dataset formats, and most functions accept data represented with objects from the pandas or numpy libraries as well as built-in Python types like lists and dictionaries. Understanding the usage patterns associated with these different options will help you quickly create useful visualizations for nearly any dataset.", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_22", "url": "https://seaborn.pydata.org/tutorial/data_structure.html", "title": "Long-form vs. wide-form data#", "page_title": "Data structures accepted by seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Long-form vs. wide-form data#", "content": "Long-form vs. wide-form data# Most plotting functions in seaborn are oriented towards vectors of data. When plotting x against y, each variable should be a vector. Seaborn accepts data sets that have more than one vector organized in some tabular fashion. There is a fundamental distinction between “long-form” and “wide-form” data tables, and seaborn will treat each differently.", "prev_chunk_id": "chunk_21", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_23", "url": "https://seaborn.pydata.org/tutorial/data_structure.html", "title": "Long-form data#", "page_title": "Data structures accepted by seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Long-form data#", "content": "Long-form data# A long-form data table has the following characteristics: - Each variable is a column - Each observation is a row As a simple example, consider the “flights” dataset, which records the number of airline passengers who flew in each month from 1949 to 1960. This dataset has three variables (year, month, and number of passengers): flights = sns.load_dataset(\"flights\") flights.head() With long-form data, columns in the table are given roles in the plot by explicitly assigning them to one of the variables. For example, making a monthly plot of the number of passengers per year looks like this: sns.relplot(data=flights, x=\"year\", y=\"passengers\", hue=\"month\", kind=\"line\")", "prev_chunk_id": "chunk_22", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_24", "url": "https://seaborn.pydata.org/tutorial/data_structure.html", "title": "Wide-form data#", "page_title": "Data structures accepted by seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Wide-form data#", "content": "Wide-form data# For simple datasets, it is often more intuitive to think about data the way it might be viewed in a spreadsheet, where the columns and rows contain levels of different variables. For example, we can convert the flights dataset into a wide-form organization by “pivoting” it so that each column has each month’s time series over years: flights_wide = flights.pivot(index=\"year\", columns=\"month\", values=\"passengers\") flights_wide.head() Here we have the same three variables, but they are organized differently. The variables in this dataset are linked to the dimensions of the table, rather than to named fields. Each observation is defined by both the value at a cell in the table and the coordinates of that cell with respect to the row and column indices. With long-form data, we can access variables in the dataset by their name. That is not the case with wide-form data. Nevertheless, because there is a clear association between the dimensions of the table and the variable in the dataset, seaborn is able to assign those variables roles in the plot. sns.relplot(data=flights_wide, kind=\"line\")", "prev_chunk_id": "chunk_23", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_25", "url": "https://seaborn.pydata.org/tutorial/data_structure.html", "title": "Messy data#", "page_title": "Data structures accepted by seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Messy data#", "content": "Messy data# Many datasets cannot be clearly interpreted using either long-form or wide-form rules. If datasets that are clearly long-form or wide-form are “tidy”, we might say that these more ambiguous datasets are “messy”. In a messy dataset, the variables are neither uniquely defined by the keys nor by the dimensions of the table. This often occurs with repeated-measures data, where it is natural to organize a table such that each row corresponds to the unit of data collection. Consider this simple dataset from a psychology experiment in which twenty subjects performed a memory task where they studied anagrams while their attention was either divided or focused: anagrams = sns.load_dataset(\"anagrams\") anagrams The attention variable is between-subjects, but there is also a within-subjects variable: the number of possible solutions to the anagrams, which varied from 1 to 3. The dependent measure is a score of memory performance. These two variables (number and score) are jointly encoded across several columns. As a result, the whole dataset is neither clearly long-form nor clearly wide-form. How might we tell seaborn to plot the average score as a function of attention and number of solutions? We’d first need to coerce the data into one of our two structures. Let’s transform it to a tidy long-form table, such that each variable is a column and each row is an observation. We can use the method pandas.DataFrame.melt() to accomplish this task: anagrams_long = anagrams.melt(id_vars=[\"subidr\", \"attnr\"], var_name=\"solutions\", value_name=\"score\") anagrams_long.head() Now we can make the plot that we want: sns.catplot(data=anagrams_long, x=\"solutions\", y=\"score\", hue=\"attnr\", kind=\"point\")", "prev_chunk_id": "chunk_24", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_26", "url": "https://seaborn.pydata.org/tutorial/data_structure.html", "title": "Further reading and take-home points#", "page_title": "Data structures accepted by seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Further reading and take-home points#", "content": "Further reading and take-home points# For a longer discussion about tabular data structures, you could read the “Tidy Data” paper by Hadley Whickham. Note that seaborn uses a slightly different set of concepts than are defined in the paper. While the paper associates tidyness with long-form structure, we have drawn a distinction between “tidy wide-form” data, where there is a clear mapping between variables in the dataset and the dimensions of the table, and “messy data”, where no such mapping exists. The long-form structure has clear advantages. It allows you to create figures by explicitly assigning variables in the dataset to roles in plot, and you can do so with more than three variables. When possible, try to represent your data with a long-form structure when embarking on serious analysis. Most of the examples in the seaborn documentation will use long-form data. But in cases where it is more natural to keep the dataset wide, remember that seaborn can remain useful.", "prev_chunk_id": "chunk_25", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_27", "url": "https://seaborn.pydata.org/tutorial/data_structure.html", "title": "Options for visualizing long-form data#", "page_title": "Data structures accepted by seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Options for visualizing long-form data#", "content": "Options for visualizing long-form data# While long-form data has a precise definition, seaborn is fairly flexible in terms of how it is actually organized across the data structures in memory. The examples in the rest of the documentation will typically use pandas.DataFrame objects and reference variables in them by assigning names of their columns to the variables in the plot. But it is also possible to store vectors in a Python dictionary or a class that implements that interface: flights_dict = flights.to_dict() sns.relplot(data=flights_dict, x=\"year\", y=\"passengers\", hue=\"month\", kind=\"line\") Many pandas operations, such as the split-apply-combine operations of a group-by, will produce a dataframe where information has moved from the columns of the input dataframe to the index of the output. So long as the name is retained, you can still reference the data as normal: flights_avg = flights.groupby(\"year\").mean(numeric_only=True) sns.relplot(data=flights_avg, x=\"year\", y=\"passengers\", kind=\"line\") Additionally, it’s possible to pass vectors of data directly as arguments to x, y, and other plotting variables. If these vectors are pandas objects, the name attribute will be used to label the plot: year = flights_avg.index passengers = flights_avg[\"passengers\"] sns.relplot(x=year, y=passengers, kind=\"line\") Numpy arrays and other objects that implement the Python sequence interface work too, but if they don’t have names, the plot will not be as informative without further tweaking: sns.relplot(x=year.to_numpy(), y=passengers.to_list(), kind=\"line\")", "prev_chunk_id": "chunk_26", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_28", "url": "https://seaborn.pydata.org/tutorial/data_structure.html", "title": "Options for visualizing wide-form data#", "page_title": "Data structures accepted by seaborn — seaborn 0.13.2 documentation", "breadcrumbs": "Options for visualizing wide-form data#", "content": "Options for visualizing wide-form data# The options for passing wide-form data are even more flexible. As with long-form data, pandas objects are preferable because the name (and, in some cases, index) information can be used. But in essence, any format that can be viewed as a single vector or a collection of vectors can be passed to data, and a valid plot can usually be constructed. The example we saw above used a rectangular pandas.DataFrame, which can be thought of as a collection of its columns. A dict or list of pandas objects will also work, but we’ll lose the axis labels: flights_wide_list = [col for _, col in flights_wide.items()] sns.relplot(data=flights_wide_list, kind=\"line\") The vectors in a collection do not need to have the same length. If they have an index, it will be used to align them: two_series = [flights_wide.loc[:1955, \"Jan\"], flights_wide.loc[1952:, \"Aug\"]] sns.relplot(data=two_series, kind=\"line\") Whereas an ordinal index will be used for numpy arrays or simple Python sequences: two_arrays = [s.to_numpy() for s in two_series] sns.relplot(data=two_arrays, kind=\"line\") But a dictionary of such vectors will at least use the keys: two_arrays_dict = {s.name: s.to_numpy() for s in two_series} sns.relplot(data=two_arrays_dict, kind=\"line\") Rectangular numpy arrays are treated just like a dataframe without index information, so they are viewed as a collection of column vectors. Note that this is different from how numpy indexing operations work, where a single indexer will access a row. But it is consistent with how pandas would turn the array into a dataframe or how matplotlib would plot it: flights_array = flights_wide.to_numpy() sns.relplot(data=flights_array, kind=\"line\")", "prev_chunk_id": "chunk_27", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_29", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "The seaborn.objects interface#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "The seaborn.objects interface#", "content": "The seaborn.objects interface# The seaborn.objects namespace was introduced in version 0.12 as a completely new interface for making seaborn plots. It offers a more consistent and flexible API, comprising a collection of composable classes for transforming and plotting data. In contrast to the existing seaborn functions, the new interface aims to support end-to-end plot specification and customization without dropping down to matplotlib (although it will remain possible to do so if necessary).", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_30", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Specifying a plot and mapping data#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Specifying a plot and mapping data#", "content": "Specifying a plot and mapping data# The objects interface should be imported with the following convention: import seaborn.objects as so The seaborn.objects namespace will provide access to all of the relevant classes. The most important is Plot. You specify plots by instantiating a Plot object and calling its methods. Let’s see a simple example: ( so.Plot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\") .add(so.Dot()) ) This code, which produces a scatter plot, should look reasonably familiar. Just as when using seaborn.scatterplot(), we passed a tidy dataframe (penguins) and assigned two of its columns to the x and y coordinates of the plot. But instead of starting with the type of chart and then adding some data assignments, here we started with the data assignments and then added a graphical element.", "prev_chunk_id": "chunk_29", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_31", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Setting properties#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Setting properties#", "content": "Setting properties# The Dot class is an example of a Mark: an object that graphically represents data values. Each mark will have a number of properties that can be set to change its appearance: ( so.Plot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\") .add(so.Dot(color=\"g\", pointsize=4)) )", "prev_chunk_id": "chunk_30", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_32", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Mapping properties#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Mapping properties#", "content": "Mapping properties# As with seaborn’s functions, it is also possible to map data values to various graphical properties: ( so.Plot( penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\", pointsize=\"body_mass_g\", ) .add(so.Dot()) ) While this basic functionality is not novel, an important difference from the function API is that properties are mapped using the same parameter names that would set them directly (instead of having hue vs. color, etc.). What matters is where the property is defined: passing a value when you initialize Dot will set it directly, whereas assigning a variable when you set up the Plot will map the corresponding data. Beyond this difference, the objects interface also allows a much wider range of mark properties to be mapped: ( so.Plot( penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", edgecolor=\"sex\", edgewidth=\"body_mass_g\", ) .add(so.Dot(color=\".8\")) )", "prev_chunk_id": "chunk_31", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_33", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Defining groups#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Defining groups#", "content": "Defining groups# The Dot mark represents each data point independently, so the assignment of a variable to a property only has the effect of changing each dot’s appearance. For marks that group or connect observations, such as Line, it also determines the number of distinct graphical elements: ( so.Plot(healthexp, x=\"Year\", y=\"Life_Expectancy\", color=\"Country\") .add(so.Line()) ) It is also possible to define a grouping without changing any visual properties, by using group: ( so.Plot(healthexp, x=\"Year\", y=\"Life_Expectancy\", group=\"Country\") .add(so.Line()) )", "prev_chunk_id": "chunk_32", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_34", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Statistical transformation#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Statistical transformation#", "content": "Statistical transformation# As with many seaborn functions, the objects interface supports statistical transformations. These are performed by Stat objects, such as Agg: ( so.Plot(penguins, x=\"species\", y=\"body_mass_g\") .add(so.Bar(), so.Agg()) ) In the function interface, statistical transformations are possible with some visual representations (e.g. seaborn.barplot()) but not others (e.g. seaborn.scatterplot()). The objects interface more cleanly separates representation and transformation, allowing you to compose Mark and Stat objects: ( so.Plot(penguins, x=\"species\", y=\"body_mass_g\") .add(so.Dot(pointsize=10), so.Agg()) ) When forming groups by mapping properties, the Stat transformation is applied to each group separately: ( so.Plot(penguins, x=\"species\", y=\"body_mass_g\", color=\"sex\") .add(so.Dot(pointsize=10), so.Agg()) )", "prev_chunk_id": "chunk_33", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_35", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Resolving overplotting#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Resolving overplotting#", "content": "Resolving overplotting# Some seaborn functions also have mechanisms that automatically resolve overplotting, as when seaborn.barplot() “dodges” bars once hue is assigned. The objects interface has less complex default behavior. Bars representing multiple groups will overlap by default: ( so.Plot(penguins, x=\"species\", y=\"body_mass_g\", color=\"sex\") .add(so.Bar(), so.Agg()) ) Nevertheless, it is possible to compose the Bar mark with the Agg stat and a second transformation, implemented by Dodge: ( so.Plot(penguins, x=\"species\", y=\"body_mass_g\", color=\"sex\") .add(so.Bar(), so.Agg(), so.Dodge()) ) The Dodge class is an example of a Move transformation, which is like a Stat but only adjusts x and y coordinates. The Move classes can be applied with any mark, and it’s not necessary to use a Stat first: ( so.Plot(penguins, x=\"species\", y=\"body_mass_g\", color=\"sex\") .add(so.Dot(), so.Dodge()) ) It’s also possible to apply multiple Move operations in sequence: ( so.Plot(penguins, x=\"species\", y=\"body_mass_g\", color=\"sex\") .add(so.Dot(), so.Dodge(), so.Jitter(.3)) )", "prev_chunk_id": "chunk_34", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_36", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Creating variables through transformation#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Creating variables through transformation#", "content": "Creating variables through transformation# The Agg stat requires both x and y to already be defined, but variables can also be created through statistical transformation. For example, the Hist stat requires only one of x or y to be defined, and it will create the other by counting observations: ( so.Plot(penguins, x=\"species\") .add(so.Bar(), so.Hist()) ) The Hist stat will also create new x values (by binning) when given numeric data: ( so.Plot(penguins, x=\"flipper_length_mm\") .add(so.Bars(), so.Hist()) ) Notice how we used Bars, rather than Bar for the plot with the continuous x axis. These two marks are related, but Bars has different defaults and works better for continuous histograms. It also produces a different, more efficient matplotlib artist. You will find the pattern of singular/plural marks elsewhere. The plural version is typically optimized for cases with larger numbers of marks. Some transforms accept both x and y, but add interval data for each coordinate. This is particularly relevant for plotting error bars after aggregating: ( so.Plot(penguins, x=\"body_mass_g\", y=\"species\", color=\"sex\") .add(so.Range(), so.Est(errorbar=\"sd\"), so.Dodge()) .add(so.Dot(), so.Agg(), so.Dodge()) )", "prev_chunk_id": "chunk_35", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_37", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Orienting marks and transforms#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Orienting marks and transforms#", "content": "Orienting marks and transforms# When aggregating, dodging, and drawing a bar, the x and y variables are treated differently. Each operation has the concept of an orientation. The Plot tries to determine the orientation automatically based on the data types of the variables. For instance, if we flip the assignment of species and body_mass_g, we’ll get the same plot, but oriented horizontally: ( so.Plot(penguins, x=\"body_mass_g\", y=\"species\", color=\"sex\") .add(so.Bar(), so.Agg(), so.Dodge()) ) Sometimes, the correct orientation is ambiguous, as when both the x and y variables are numeric. In these cases, you can be explicit by passing the orient parameter to Plot.add(): ( so.Plot(tips, x=\"total_bill\", y=\"size\", color=\"time\") .add(so.Bar(), so.Agg(), so.Dodge(), orient=\"y\") )", "prev_chunk_id": "chunk_36", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_38", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Building and displaying the plot#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Building and displaying the plot#", "content": "Building and displaying the plot# Most examples this far have produced a single subplot with just one kind of mark on it. But Plot does not limit you to this.", "prev_chunk_id": "chunk_37", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_39", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Adding multiple layers#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Adding multiple layers#", "content": "Adding multiple layers# More complex single-subplot graphics can be created by calling Plot.add() repeatedly. Each time it is called, it defines a layer in the plot. For example, we may want to add a scatterplot (now using Dots) and then a regression fit: ( so.Plot(tips, x=\"total_bill\", y=\"tip\") .add(so.Dots()) .add(so.Line(), so.PolyFit()) ) Variable mappings that are defined in the Plot constructor will be used for all layers: ( so.Plot(tips, x=\"total_bill\", y=\"tip\", color=\"time\") .add(so.Dots()) .add(so.Line(), so.PolyFit()) )", "prev_chunk_id": "chunk_38", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_40", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Layer-specific mappings#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Layer-specific mappings#", "content": "Layer-specific mappings# You can also define a mapping such that it is used only in a specific layer. This is accomplished by defining the mapping within the call to Plot.add for the relevant layer: ( so.Plot(tips, x=\"total_bill\", y=\"tip\") .add(so.Dots(), color=\"time\") .add(so.Line(color=\".2\"), so.PolyFit()) ) Alternatively, define the layer for the entire plot, but remove it from a specific layer by setting the variable to None: ( so.Plot(tips, x=\"total_bill\", y=\"tip\", color=\"time\") .add(so.Dots()) .add(so.Line(color=\".2\"), so.PolyFit(), color=None) ) To recap, there are three ways to specify the value of a mark property: (1) by mapping a variable in all layers, (2) by mapping a variable in a specific layer, and (3) by setting the property directly:", "prev_chunk_id": "chunk_39", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_41", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Faceting and pairing subplots#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Faceting and pairing subplots#", "content": "Faceting and pairing subplots# As with seaborn’s figure-level functions (seaborn.displot(), seaborn.catplot(), etc.), the Plot interface can also produce figures with multiple “facets”, or subplots containing subsets of data. This is accomplished with the Plot.facet() method: ( so.Plot(penguins, x=\"flipper_length_mm\") .facet(\"species\") .add(so.Bars(), so.Hist()) ) Call Plot.facet() with the variables that should be used to define the columns and/or rows of the plot: ( so.Plot(penguins, x=\"flipper_length_mm\") .facet(col=\"species\", row=\"sex\") .add(so.Bars(), so.Hist()) ) You can facet using a variable with a larger number of levels by “wrapping” across the other dimension: ( so.Plot(healthexp, x=\"Year\", y=\"Life_Expectancy\") .facet(col=\"Country\", wrap=3) .add(so.Line()) ) All layers will be faceted unless you explicitly exclude them, which can be useful for providing additional context on each subplot: ( so.Plot(healthexp, x=\"Year\", y=\"Life_Expectancy\") .facet(\"Country\", wrap=3) .add(so.Line(alpha=.3), group=\"Country\", col=None) .add(so.Line(linewidth=3)) ) An alternate way to produce subplots is Plot.pair(). Like seaborn.PairGrid, this draws all of the data on each subplot, using different variables for the x and/or y coordinates: ( so.Plot(penguins, y=\"body_mass_g\", color=\"species\") .pair(x=[\"bill_length_mm\", \"bill_depth_mm\"]) .add(so.Dots()) ) You can combine faceting and pairing so long as the operations add subplots on opposite dimensions: ( so.Plot(penguins, y=\"body_mass_g\", color=\"species\") .pair(x=[\"bill_length_mm\", \"bill_depth_mm\"]) .facet(row=\"sex\") .add(so.Dots()) )", "prev_chunk_id": "chunk_40", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_42", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Integrating with matplotlib#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Integrating with matplotlib#", "content": "Integrating with matplotlib# There may be cases where you want multiple subplots to appear in a figure with a more complex structure than what Plot.facet() or Plot.pair() can provide. The current solution is to delegate figure setup to matplotlib and to supply the matplotlib object that Plot should use with the Plot.on() method. This object can be either a matplotlib.axes.Axes, matplotlib.figure.Figure, or matplotlib.figure.SubFigure; the latter is most useful for constructing bespoke subplot layouts: f = mpl.figure.Figure(figsize=(8, 4)) sf1, sf2 = f.subfigures(1, 2) ( so.Plot(penguins, x=\"body_mass_g\", y=\"flipper_length_mm\") .add(so.Dots()) .on(sf1) .plot() ) ( so.Plot(penguins, x=\"body_mass_g\") .facet(row=\"sex\") .add(so.Bars(), so.Hist()) .on(sf2) .plot() )", "prev_chunk_id": "chunk_41", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_43", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Building and displaying the plot#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Building and displaying the plot#", "content": "Building and displaying the plot# An important thing to know is that Plot methods clone the object they are called on and return that clone instead of updating the object in place. This means that you can define a common plot spec and then produce several variations on it. So, take this basic specification: p = so.Plot(healthexp, \"Year\", \"Spending_USD\", color=\"Country\") We could use it to draw a line plot: p.add(so.Line()) Or perhaps a stacked area plot: p.add(so.Area(), so.Stack()) The Plot methods are fully declarative. Calling them updates the plot spec, but it doesn’t actually do any plotting. One consequence of this is that methods can be called in any order, and many of them can be called multiple times. When does the plot actually get rendered? Plot is optimized for use in notebook environments. The rendering is automatically triggered when the Plot gets displayed in the Jupyter REPL. That’s why we didn’t see anything in the example above, where we defined a Plot but assigned it to p rather than letting it return out to the REPL. To see a plot in a notebook, either return it from the final line of a cell or call Jupyter’s built-in display function on the object. The notebook integration bypasses matplotlib.pyplot entirely, but you can use its figure-display machinery in other contexts by calling Plot.show(). You can also save the plot to a file (or buffer) by calling Plot.save().", "prev_chunk_id": "chunk_42", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_44", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Customizing the appearance#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Customizing the appearance#", "content": "Customizing the appearance# The new interface aims to support a deep amount of customization through Plot, reducing the need to switch gears and use matplotlib functionality directly. (But please be patient; not all of the features needed to achieve this goal have been implemented!)", "prev_chunk_id": "chunk_43", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_45", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Parameterizing scales#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Parameterizing scales#", "content": "Parameterizing scales# All of the data-dependent properties are controlled by the concept of a Scale and the Plot.scale() method. This method accepts several different types of arguments. One possibility, which is closest to the use of scales in matplotlib, is to pass the name of a function that transforms the coordinates: ( so.Plot(diamonds, x=\"carat\", y=\"price\") .add(so.Dots()) .scale(y=\"log\") ) Plot.scale() can also control the mappings for semantic properties like color. You can directly pass it any argument that you would pass to the palette parameter in seaborn’s function interface: ( so.Plot(diamonds, x=\"carat\", y=\"price\", color=\"clarity\") .add(so.Dots()) .scale(color=\"flare\") ) Another option is to provide a tuple of (min, max) values, controlling the range that the scale should map into. This works both for numeric properties and for colors: ( so.Plot(diamonds, x=\"carat\", y=\"price\", color=\"clarity\", pointsize=\"carat\") .add(so.Dots()) .scale(color=(\"#88c\", \"#555\"), pointsize=(2, 10)) ) For additional control, you can pass a Scale object. There are several different types of Scale, each with appropriate parameters. For example, Continuous lets you define the input domain (norm), the output range (values), and the function that maps between them (trans), while Nominal allows you to specify an ordering: ( so.Plot(diamonds, x=\"carat\", y=\"price\", color=\"carat\", marker=\"cut\") .add(so.Dots()) .scale( color=so.Continuous(\"crest\", norm=(0, 3), trans=\"sqrt\"), marker=so.Nominal([\"o\", \"+\", \"x\"], order=[\"Ideal\", \"Premium\", \"Good\"]), ) )", "prev_chunk_id": "chunk_44", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_46", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Customizing legends and ticks#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Customizing legends and ticks#", "content": "Customizing legends and ticks# The Scale objects are also how you specify which values should appear as tick labels / in the legend, along with how they appear. For example, the Continuous.tick() method lets you control the density or locations of the ticks, and the Continuous.label() method lets you modify the format: ( so.Plot(diamonds, x=\"carat\", y=\"price\", color=\"carat\") .add(so.Dots()) .scale( x=so.Continuous().tick(every=0.5), y=so.Continuous().label(like=\"${x:.0f}\"), color=so.Continuous().tick(at=[1, 2, 3, 4]), ) )", "prev_chunk_id": "chunk_45", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_47", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Customizing limits, labels, and titles#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Customizing limits, labels, and titles#", "content": "Customizing limits, labels, and titles# Plot has a number of methods for simple customization, including Plot.label(), Plot.limit(), and Plot.share(): ( so.Plot(penguins, x=\"body_mass_g\", y=\"species\", color=\"island\") .facet(col=\"sex\") .add(so.Dot(), so.Jitter(.5)) .share(x=False) .limit(y=(2.5, -.5)) .label( x=\"Body mass (g)\", y=\"\", color=str.capitalize, title=\"{} penguins\".format, ) )", "prev_chunk_id": "chunk_46", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_48", "url": "https://seaborn.pydata.org/tutorial/objects_interface.html", "title": "Theme customization#", "page_title": "The seaborn.objects interface — seaborn 0.13.2 documentation", "breadcrumbs": "Theme customization#", "content": "Theme customization# Finally, Plot supports data-independent theming through the Plot.theme method. Currently, this method accepts a dictionary of matplotlib rc parameters. You can set them directly and/or pass a package of parameters from seaborn’s theming functions: from seaborn import axes_style theme_dict = {**axes_style(\"whitegrid\"), \"grid.linestyle\": \":\"} so.Plot().theme(theme_dict) To change the theme for all Plot instances, update the settings in Plot.config: so.Plot.config.theme.update(theme_dict)", "prev_chunk_id": "chunk_47", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_49", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "x, y, xmin, xmax, ymin, ymax#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "x, y, xmin, xmax, ymin, ymax#", "content": "x, y, xmin, xmax, ymin, ymax# Coordinate properties determine where a mark is drawn on a plot. Canonically, the x coordinate is the horizontal position and the y coordinate is the vertical position. Some marks accept a span (i.e., min, max) parameterization for one or both variables. Others may accept x and y but also use a baseline parameter to show a span. The layer’s orient parameter determines how this works. If a variable does not contain numeric data, its scale will apply a conversion so that data can be drawn on a screen. For instance, Nominal scales assign an integer index to each distinct category, and Temporal scales represent dates as the number of days from a reference “epoch”: A Continuous scale can also apply a nonlinear transform between data values and spatial positions:", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_50", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "color, fillcolor, edgecolor#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "color, fillcolor, edgecolor#", "content": "color, fillcolor, edgecolor# All marks can be given a color, and many distinguish between the color of the mark’s “edge” and “fill”. Often, simply using color will set both, while the more-specific properties allow further control: When the color property is mapped, the default palette depends on the type of scale. Nominal scales use discrete, unordered hues, while continuous scales (including temporal ones) use a sequential gradient: Color scales are parameterized by the name of a palette, such as 'viridis', 'rocket', or 'deep'. Some palette names can include parameters, including simple gradients (e.g. 'dark:blue') or the cubehelix system (e.g. 'ch:start=.2,rot=-.4`). See the color palette tutorial for guidance on making an appropriate selection. Continuous scales can also be parameterized by a tuple of colors that the scale should interpolate between. When using a nominal scale, it is possible to provide either the name of the palette (which will be discretely-sampled, if necessary), a list of individual color values, or a dictionary directly mapping data values to colors. Individual colors may be specified in a wide range of formats. These include indexed references to the current color cycle ('C0'), single-letter shorthands ('b'), grayscale values ('.4'), RGB hex codes ('#4c72b0'), X11 color names ('seagreen'), and XKCD color survey names ('purpleish'):", "prev_chunk_id": "chunk_49", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_51", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "alpha, fillalpha, edgealpha#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "alpha, fillalpha, edgealpha#", "content": "alpha, fillalpha, edgealpha# The alpha property determines the mark’s opacity. Lowering the alpha can be helpful for representing density in the case of overplotting: Mapping the alpha property can also be useful even when marks do not overlap because it conveys a sense of importance and can be combined with a color scale to represent two variables. Moreover, colors with lower alpha appear less saturated, which can improve the appearance of larger filled marks (such as bars). As with color, some marks define separate edgealpha and fillalpha properties for additional control.", "prev_chunk_id": "chunk_50", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_52", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "fill#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "fill#", "content": "fill# The fill property is relevant to marks with a distinction between the edge and interior and determines whether the interior is visible. It is a boolean state: fill can be set only to True or False:", "prev_chunk_id": "chunk_51", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_53", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "marker#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "marker#", "content": "marker# The marker property is relevant for dot marks and some line marks. The API for specifying markers is very flexible, as detailed in the matplotlib API docs: matplotlib.markers. Markers can be specified using a number of simple string codes: They can also be programatically generated using a (num_sides, fill_style, angle) tuple: See the matplotlib docs for additional formats, including mathtex character codes ('$...$') and arrays of vertices. A marker property is always mapped with a nominal scale; there is no inherent ordering to the different shapes. If no scale is provided, the plot will programmatically generate a suitably large set of unique markers: While this ensures that the shapes are technically distinct, bear in mind that — in most cases — it will be difficult to tell the markers apart if more than a handful are used in a single plot.", "prev_chunk_id": "chunk_52", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_54", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "linestyle, edgestyle#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "linestyle, edgestyle#", "content": "linestyle, edgestyle# The linestyle property is relevant to line marks, and the edgestyle property is relevant to a number of marks with “edges. Both properties determine the “dashing” of a line in terms of on-off segments. Dashes can be specified with a small number of shorthand codes ('-', '--', '-.', and ':') or programatically using (on, off, ...) tuples. In the tuple specification, the unit is equal to the linewidth:", "prev_chunk_id": "chunk_53", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_55", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "pointsize#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "pointsize#", "content": "pointsize# The pointsize property is relevant to dot marks and to line marks that can show markers at individual data points. The units correspond to the diameter of the mark in points. Note that, while the parameterization corresponds to diameter, scales will be applied with a square root transform so that data values are linearly proportional to area:", "prev_chunk_id": "chunk_54", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_56", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "linewidth#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "linewidth#", "content": "linewidth# The linewidth property is relevant to line marks and determines their thickness. The value should be non-negative and has point units:", "prev_chunk_id": "chunk_55", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_57", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "edgewidth#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "edgewidth#", "content": "edgewidth# The edgewidth property is akin to linewidth but applies to marks with an edge/fill rather than to lines. It also has a different default range when used in a scale. The units are the same:", "prev_chunk_id": "chunk_56", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_58", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "stroke#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "stroke#", "content": "stroke# The stroke property is akin to edgewidth but applies when a dot mark is defined by its stroke rather than its fill. It also has a slightly different default scale range, but otherwise behaves similarly:", "prev_chunk_id": "chunk_57", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_59", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "halign, valign#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "halign, valign#", "content": "halign, valign# The halign and valign properties control the horizontal and vertical alignment of text marks. The options for horizontal alignment are 'left', 'right', and 'center', while the options for vertical alignment are 'top', 'bottom', 'center', 'baseline', and 'center_baseline'.", "prev_chunk_id": "chunk_58", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_60", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "fontsize#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "fontsize#", "content": "fontsize# The fontsize property controls the size of textual marks. The value has point units:", "prev_chunk_id": "chunk_59", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_61", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "offset#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "offset#", "content": "offset# The offset property controls the spacing between a text mark and its anchor position. It applies when not using center alignment (i.e., when using left/right or top/bottom). The value has point units.", "prev_chunk_id": "chunk_60", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_62", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "text#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "text#", "content": "text# The text property is used to set the content of a textual mark. It is always used literally (not mapped), and cast to string when necessary.", "prev_chunk_id": "chunk_61", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_63", "url": "https://seaborn.pydata.org/tutorial/properties.html", "title": "group#", "page_title": "Properties of Mark objects — seaborn 0.13.2 documentation", "breadcrumbs": "group#", "content": "group# The group property is special in that it does not change anything about the mark’s appearance but defines additional data subsets that transforms should operate on independently.", "prev_chunk_id": "chunk_62", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_64", "url": "https://seaborn.pydata.org/tutorial/relational.html", "title": "Visualizing statistical relationships#", "page_title": "Visualizing statistical relationships — seaborn 0.13.2 documentation", "breadcrumbs": "Visualizing statistical relationships#", "content": "Visualizing statistical relationships# Statistical analysis is a process of understanding how variables in a dataset relate to each other and how those relationships depend on other variables. Visualization can be a core component of this process because, when data are visualized properly, the human visual system can see trends and patterns that indicate a relationship. We will discuss three seaborn functions in this tutorial. The one we will use most is relplot(). This is a figure-level function for visualizing statistical relationships using two common approaches: scatter plots and line plots. relplot() combines a FacetGrid with one of two axes-level functions: - scatterplot()(withkind=\"scatter\"; the default) - lineplot()(withkind=\"line\") As we will see, these functions can be quite illuminating because they use simple and easily-understood representations of data that can nevertheless represent complex dataset structures. They can do so because they plot two-dimensional graphics that can be enhanced by mapping up to three additional variables using the semantics of hue, size, and style. import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns sns.set_theme(style=\"darkgrid\")", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_65", "url": "https://seaborn.pydata.org/tutorial/relational.html", "title": "Relating variables with scatter plots#", "page_title": "Visualizing statistical relationships — seaborn 0.13.2 documentation", "breadcrumbs": "Relating variables with scatter plots#", "content": "Relating variables with scatter plots# The scatter plot is a mainstay of statistical visualization. It depicts the joint distribution of two variables using a cloud of points, where each point represents an observation in the dataset. This depiction allows the eye to infer a substantial amount of information about whether there is any meaningful relationship between them. There are several ways to draw a scatter plot in seaborn. The most basic, which should be used when both variables are numeric, is the scatterplot() function. In the categorical visualization tutorial, we will see specialized tools for using scatterplots to visualize categorical data. The scatterplot() is the default kind in relplot() (it can also be forced by setting kind=\"scatter\"): tips = sns.load_dataset(\"tips\") sns.relplot(data=tips, x=\"total_bill\", y=\"tip\")", "prev_chunk_id": "chunk_64", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_66", "url": "https://seaborn.pydata.org/tutorial/relational.html", "title": "Emphasizing continuity with line plots#", "page_title": "Visualizing statistical relationships — seaborn 0.13.2 documentation", "breadcrumbs": "Emphasizing continuity with line plots#", "content": "Emphasizing continuity with line plots# Scatter plots are highly effective, but there is no universally optimal type of visualisation. Instead, the visual representation should be adapted for the specifics of the dataset and to the question you are trying to answer with the plot. With some datasets, you may want to understand changes in one variable as a function of time, or a similarly continuous variable. In this situation, a good choice is to draw a line plot. In seaborn, this can be accomplished by the lineplot() function, either directly or with relplot() by setting kind=\"line\": dowjones = sns.load_dataset(\"dowjones\") sns.relplot(data=dowjones, x=\"Date\", y=\"Price\", kind=\"line\")", "prev_chunk_id": "chunk_65", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_67", "url": "https://seaborn.pydata.org/tutorial/relational.html", "title": "Aggregation and representing uncertainty#", "page_title": "Visualizing statistical relationships — seaborn 0.13.2 documentation", "breadcrumbs": "Aggregation and representing uncertainty#", "content": "Aggregation and representing uncertainty# More complex datasets will have multiple measurements for the same value of the x variable. The default behavior in seaborn is to aggregate the multiple measurements at each x value by plotting the mean and the 95% confidence interval around the mean: fmri = sns.load_dataset(\"fmri\") sns.relplot(data=fmri, x=\"timepoint\", y=\"signal\", kind=\"line\") The confidence intervals are computed using bootstrapping, which can be time-intensive for larger datasets. It’s therefore possible to disable them: sns.relplot( data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", errorbar=None, ) Another good option, especially with larger data, is to represent the spread of the distribution at each timepoint by plotting the standard deviation instead of a confidence interval: sns.relplot( data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", errorbar=\"sd\", ) To turn off aggregation altogether, set the estimator parameter to None This might produce a strange effect when the data have multiple observations at each point. sns.relplot( data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", estimator=None, )", "prev_chunk_id": "chunk_66", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_68", "url": "https://seaborn.pydata.org/tutorial/relational.html", "title": "Plotting subsets of data with semantic mappings#", "page_title": "Visualizing statistical relationships — seaborn 0.13.2 documentation", "breadcrumbs": "Plotting subsets of data with semantic mappings#", "content": "Plotting subsets of data with semantic mappings# The lineplot() function has the same flexibility as scatterplot(): it can show up to three additional variables by modifying the hue, size, and style of the plot elements. It does so using the same API as scatterplot(), meaning that we don’t need to stop and think about the parameters that control the look of lines vs. points in matplotlib. Using semantics in lineplot() will also determine how the data get aggregated. For example, adding a hue semantic with two levels splits the plot into two lines and error bands, coloring each to indicate which subset of the data they correspond to. sns.relplot( data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", hue=\"event\", ) Adding a style semantic to a line plot changes the pattern of dashes in the line by default: sns.relplot( data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", hue=\"region\", style=\"event\", ) But you can identify subsets by the markers used at each observation, either together with the dashes or instead of them: sns.relplot( data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", hue=\"region\", style=\"event\", dashes=False, markers=True, ) As with scatter plots, be cautious about making line plots using multiple semantics. While sometimes informative, they can also be difficult to parse and interpret. But even when you are only examining changes across one additional variable, it can be useful to alter both the color and style of the lines. This can make the plot more accessible when printed to black-and-white or viewed by someone with color blindness: sns.relplot( data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", hue=\"event\", style=\"event\", ) When you are working with repeated measures data (that is, you have units that were sampled multiple times), you can also plot each sampling unit separately without distinguishing them through semantics. This avoids cluttering the legend: sns.relplot( data=fmri.query(\"event == 'stim'\"), kind=\"line\", x=\"timepoint\", y=\"signal\", hue=\"region\", units=\"subject\", estimator=None, ) The default colormap and", "prev_chunk_id": "chunk_67", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_69", "url": "https://seaborn.pydata.org/tutorial/relational.html", "title": "Plotting subsets of data with semantic mappings#", "page_title": "Visualizing statistical relationships — seaborn 0.13.2 documentation", "breadcrumbs": "Plotting subsets of data with semantic mappings#", "content": "handling of the legend in lineplot() also depends on whether the hue semantic is categorical or numeric: dots = sns.load_dataset(\"dots\").query(\"align == 'dots'\") sns.relplot( data=dots, kind=\"line\", x=\"time\", y=\"firing_rate\", hue=\"coherence\", style=\"choice\", ) It may happen that, even though the hue variable is numeric, it is poorly represented by a linear color scale. That’s the case here, where the levels of the hue variable are logarithmically scaled. You can provide specific color values for each line by passing a list or dictionary: palette = sns.cubehelix_palette(light=.8, n_colors=6) sns.relplot( data=dots, kind=\"line\", x=\"time\", y=\"firing_rate\", hue=\"coherence\", style=\"choice\", palette=palette, ) Or you can alter how the colormap is normalized: from matplotlib.colors import LogNorm palette = sns.cubehelix_palette(light=.7, n_colors=6) sns.relplot( data=dots.query(\"coherence > 0\"), kind=\"line\", x=\"time\", y=\"firing_rate\", hue=\"coherence\", style=\"choice\", hue_norm=LogNorm(), ) The third semantic, size, changes the width of the lines: sns.relplot( data=dots, kind=\"line\", x=\"time\", y=\"firing_rate\", size=\"coherence\", style=\"choice\", ) While the size variable will typically be numeric, it’s also possible to map a categorical variable with the width of the lines. Be cautious when doing so, because it will be difficult to distinguish much more than “thick” vs “thin” lines. However, dashes can be hard to perceive when lines have high-frequency variability, so using different widths may be more effective in that case: sns.relplot( data=dots, kind=\"line\", x=\"time\", y=\"firing_rate\", hue=\"coherence\", size=\"choice\", palette=palette, )", "prev_chunk_id": "chunk_68", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_70", "url": "https://seaborn.pydata.org/tutorial/relational.html", "title": "Controlling sorting and orientation#", "page_title": "Visualizing statistical relationships — seaborn 0.13.2 documentation", "breadcrumbs": "Controlling sorting and orientation#", "content": "Controlling sorting and orientation# Because lineplot() assumes that you are most often trying to draw y as a function of x, the default behavior is to sort the data by the x values before plotting. However, this can be disabled: healthexp = sns.load_dataset(\"healthexp\").sort_values(\"Year\") sns.relplot( data=healthexp, kind=\"line\", x=\"Spending_USD\", y=\"Life_Expectancy\", hue=\"Country\", sort=False ) It’s also possible to sort (and aggregate) along the y axis: sns.relplot( data=fmri, kind=\"line\", x=\"signal\", y=\"timepoint\", hue=\"event\", orient=\"y\", )", "prev_chunk_id": "chunk_69", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_71", "url": "https://seaborn.pydata.org/tutorial/relational.html", "title": "Showing multiple relationships with facets#", "page_title": "Visualizing statistical relationships — seaborn 0.13.2 documentation", "breadcrumbs": "Showing multiple relationships with facets#", "content": "Showing multiple relationships with facets# We’ve emphasized in this tutorial that, while these functions can show several semantic variables at once, it’s not always effective to do so. But what about when you do want to understand how a relationship between two variables depends on more than one other variable? The best approach may be to make more than one plot. Because relplot() is based on the FacetGrid, this is easy to do. To show the influence of an additional variable, instead of assigning it to one of the semantic roles in the plot, use it to “facet” the visualization. This means that you make multiple axes and plot subsets of the data on each of them: sns.relplot( data=tips, x=\"total_bill\", y=\"tip\", hue=\"smoker\", col=\"time\", ) You can also show the influence of two variables this way: one by faceting on the columns and one by faceting on the rows. As you start adding more variables to the grid, you may want to decrease the figure size. Remember that the size FacetGrid is parameterized by the height and aspect ratio of each facet: sns.relplot( data=fmri, kind=\"line\", x=\"timepoint\", y=\"signal\", hue=\"subject\", col=\"region\", row=\"event\", height=3, estimator=None ) When you want to examine effects across many levels of a variable, it can be a good idea to facet that variable on the columns and then “wrap” the facets into the rows: sns.relplot( data=fmri.query(\"region == 'frontal'\"), kind=\"line\", x=\"timepoint\", y=\"signal\", hue=\"event\", style=\"event\", col=\"subject\", col_wrap=5, height=3, aspect=.75, linewidth=2.5, ) These visualizations, which are sometimes called “lattice” plots or “small-multiples”, are very effective because they present the data in a format that makes it easy for the eye to detect both overall patterns and deviations from those patterns. While you should make use of the flexibility afforded by scatterplot() and relplot(), always try to keep in mind that several simple", "prev_chunk_id": "chunk_70", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_72", "url": "https://seaborn.pydata.org/tutorial/relational.html", "title": "Showing multiple relationships with facets#", "page_title": "Visualizing statistical relationships — seaborn 0.13.2 documentation", "breadcrumbs": "Showing multiple relationships with facets#", "content": "plots are usually more effective than one complex plot.", "prev_chunk_id": "chunk_71", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_73", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Visualizing distributions of data#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Visualizing distributions of data#", "content": "Visualizing distributions of data# An early step in any effort to analyze or model data should be to understand how the variables are distributed. Techniques for distribution visualization can provide quick answers to many important questions. What range do the observations cover? What is their central tendency? Are they heavily skewed in one direction? Is there evidence for bimodality? Are there significant outliers? Do the answers to these questions vary across subsets defined by other variables? The distributions module contains several functions designed to answer questions such as these. The axes-level functions are histplot(), kdeplot(), ecdfplot(), and rugplot(). They are grouped together within the figure-level displot(), jointplot(), and pairplot() functions. There are several different approaches to visualizing a distribution, and each has its relative advantages and drawbacks. It is important to understand these factors so that you can choose the best approach for your particular aim.", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_74", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Plotting univariate histograms#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Plotting univariate histograms#", "content": "Plotting univariate histograms# Perhaps the most common approach to visualizing a distribution is the histogram. This is the default approach in displot(), which uses the same underlying code as histplot(). A histogram is a bar plot where the axis representing the data variable is divided into a set of discrete bins and the count of observations falling within each bin is shown using the height of the corresponding bar: penguins = sns.load_dataset(\"penguins\") sns.displot(penguins, x=\"flipper_length_mm\")", "prev_chunk_id": "chunk_73", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_75", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Choosing the bin size#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Choosing the bin size#", "content": "Choosing the bin size# The size of the bins is an important parameter, and using the wrong bin size can mislead by obscuring important features of the data or by creating apparent features out of random variability. By default, displot()/histplot() choose a default bin size based on the variance of the data and the number of observations. But you should not be over-reliant on such automatic approaches, because they depend on particular assumptions about the structure of your data. It is always advisable to check that your impressions of the distribution are consistent across different bin sizes. To choose the size directly, set the binwidth parameter: sns.displot(penguins, x=\"flipper_length_mm\", binwidth=3)", "prev_chunk_id": "chunk_74", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_76", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Conditioning on other variables#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Conditioning on other variables#", "content": "Conditioning on other variables# Once you understand the distribution of a variable, the next step is often to ask whether features of that distribution differ across other variables in the dataset. For example, what accounts for the bimodal distribution of flipper lengths that we saw above? displot() and histplot() provide support for conditional subsetting via the hue semantic. Assigning a variable to hue will draw a separate histogram for each of its unique values and distinguish them by color: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\") By default, the different histograms are “layered” on top of each other and, in some cases, they may be difficult to distinguish. One option is to change the visual representation of the histogram from a bar plot to a “step” plot: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\", element=\"step\") Alternatively, instead of layering each bar, they can be “stacked”, or moved vertically. In this plot, the outline of the full histogram will match the plot with only a single variable: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\", multiple=\"stack\") The stacked histogram emphasizes the part-whole relationship between the variables, but it can obscure other features (for example, it is difficult to determine the mode of the Adelie distribution. Another option is “dodge” the bars, which moves them horizontally and reduces their width. This ensures that there are no overlaps and that the bars remain comparable in terms of height. But it only works well when the categorical variable has a small number of levels: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"sex\", multiple=\"dodge\") Because displot() is a figure-level function and is drawn onto a FacetGrid, it is also possible to draw each individual distribution in a separate subplot by assigning the second variable to col or row rather than (or in addition to) hue. This represents the distribution of each subset well, but it makes it more difficult to draw direct comparisons:", "prev_chunk_id": "chunk_75", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_77", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Conditioning on other variables#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Conditioning on other variables#", "content": "sns.displot(penguins, x=\"flipper_length_mm\", col=\"sex\") None of these approaches are perfect, and we will soon see some alternatives to a histogram that are better-suited to the task of comparison.", "prev_chunk_id": "chunk_76", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_78", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Normalized histogram statistics#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Normalized histogram statistics#", "content": "Normalized histogram statistics# Before we do, another point to note is that, when the subsets have unequal numbers of observations, comparing their distributions in terms of counts may not be ideal. One solution is to normalize the counts using the stat parameter: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\", stat=\"density\") By default, however, the normalization is applied to the entire distribution, so this simply rescales the height of the bars. By setting common_norm=False, each subset will be normalized independently: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\", stat=\"density\", common_norm=False) Density normalization scales the bars so that their areas sum to 1. As a result, the density axis is not directly interpretable. Another option is to normalize the bars to that their heights sum to 1. This makes most sense when the variable is discrete, but it is an option for all histograms: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\", stat=\"probability\")", "prev_chunk_id": "chunk_77", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_79", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Kernel density estimation#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Kernel density estimation#", "content": "Kernel density estimation# A histogram aims to approximate the underlying probability density function that generated the data by binning and counting observations. Kernel density estimation (KDE) presents a different solution to the same problem. Rather than using discrete bins, a KDE plot smooths the observations with a Gaussian kernel, producing a continuous density estimate: sns.displot(penguins, x=\"flipper_length_mm\", kind=\"kde\")", "prev_chunk_id": "chunk_78", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_80", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Choosing the smoothing bandwidth#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Choosing the smoothing bandwidth#", "content": "Choosing the smoothing bandwidth# Much like with the bin size in the histogram, the ability of the KDE to accurately represent the data depends on the choice of smoothing bandwidth. An over-smoothed estimate might erase meaningful features, but an under-smoothed estimate can obscure the true shape within random noise. The easiest way to check the robustness of the estimate is to adjust the default bandwidth: sns.displot(penguins, x=\"flipper_length_mm\", kind=\"kde\", bw_adjust=.25) Note how the narrow bandwidth makes the bimodality much more apparent, but the curve is much less smooth. In contrast, a larger bandwidth obscures the bimodality almost completely: sns.displot(penguins, x=\"flipper_length_mm\", kind=\"kde\", bw_adjust=2)", "prev_chunk_id": "chunk_79", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_81", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Conditioning on other variables#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Conditioning on other variables#", "content": "Conditioning on other variables# As with histograms, if you assign a hue variable, a separate density estimate will be computed for each level of that variable: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\", kind=\"kde\") In many cases, the layered KDE is easier to interpret than the layered histogram, so it is often a good choice for the task of comparison. Many of the same options for resolving multiple distributions apply to the KDE as well, however: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\", kind=\"kde\", multiple=\"stack\") Note how the stacked plot filled in the area between each curve by default. It is also possible to fill in the curves for single or layered densities, although the default alpha value (opacity) will be different, so that the individual densities are easier to resolve. sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\", kind=\"kde\", fill=True)", "prev_chunk_id": "chunk_80", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_82", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Kernel density estimation pitfalls#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Kernel density estimation pitfalls#", "content": "Kernel density estimation pitfalls# KDE plots have many advantages. Important features of the data are easy to discern (central tendency, bimodality, skew), and they afford easy comparisons between subsets. But there are also situations where KDE poorly represents the underlying data. This is because the logic of KDE assumes that the underlying distribution is smooth and unbounded. One way this assumption can fail is when a variable reflects a quantity that is naturally bounded. If there are observations lying close to the bound (for example, small values of a variable that cannot be negative), the KDE curve may extend to unrealistic values: sns.displot(tips, x=\"total_bill\", kind=\"kde\") This can be partially avoided with the cut parameter, which specifies how far the curve should extend beyond the extreme datapoints. But this influences only where the curve is drawn; the density estimate will still smooth over the range where no data can exist, causing it to be artificially low at the extremes of the distribution: sns.displot(tips, x=\"total_bill\", kind=\"kde\", cut=0) The KDE approach also fails for discrete data or when data are naturally continuous but specific values are over-represented. The important thing to keep in mind is that the KDE will always show you a smooth curve, even when the data themselves are not smooth. For example, consider this distribution of diamond weights: diamonds = sns.load_dataset(\"diamonds\") sns.displot(diamonds, x=\"carat\", kind=\"kde\") While the KDE suggests that there are peaks around specific values, the histogram reveals a much more jagged distribution: sns.displot(diamonds, x=\"carat\") As a compromise, it is possible to combine these two approaches. While in histogram mode, displot() (as with histplot()) has the option of including the smoothed KDE curve (note kde=True, not kind=\"kde\"): sns.displot(diamonds, x=\"carat\", kde=True)", "prev_chunk_id": "chunk_81", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_83", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Empirical cumulative distributions#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Empirical cumulative distributions#", "content": "Empirical cumulative distributions# A third option for visualizing distributions computes the “empirical cumulative distribution function” (ECDF). This plot draws a monotonically-increasing curve through each datapoint such that the height of the curve reflects the proportion of observations with a smaller value: sns.displot(penguins, x=\"flipper_length_mm\", kind=\"ecdf\") The ECDF plot has two key advantages. Unlike the histogram or KDE, it directly represents each datapoint. That means there is no bin size or smoothing parameter to consider. Additionally, because the curve is monotonically increasing, it is well-suited for comparing multiple distributions: sns.displot(penguins, x=\"flipper_length_mm\", hue=\"species\", kind=\"ecdf\") The major downside to the ECDF plot is that it represents the shape of the distribution less intuitively than a histogram or density curve. Consider how the bimodality of flipper lengths is immediately apparent in the histogram, but to see it in the ECDF plot, you must look for varying slopes. Nevertheless, with practice, you can learn to answer all of the important questions about a distribution by examining the ECDF, and doing so can be a powerful approach.", "prev_chunk_id": "chunk_82", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_84", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Visualizing bivariate distributions#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Visualizing bivariate distributions#", "content": "Visualizing bivariate distributions# All of the examples so far have considered univariate distributions: distributions of a single variable, perhaps conditional on a second variable assigned to hue. Assigning a second variable to y, however, will plot a bivariate distribution: sns.displot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\") A bivariate histogram bins the data within rectangles that tile the plot and then shows the count of observations within each rectangle with the fill color (analogous to a heatmap()). Similarly, a bivariate KDE plot smoothes the (x, y) observations with a 2D Gaussian. The default representation then shows the contours of the 2D density: sns.displot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", kind=\"kde\") Assigning a hue variable will plot multiple heatmaps or contour sets using different colors. For bivariate histograms, this will only work well if there is minimal overlap between the conditional distributions: sns.displot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\") The contour approach of the bivariate KDE plot lends itself better to evaluating overlap, although a plot with too many contours can get busy: sns.displot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\", kind=\"kde\") Just as with univariate plots, the choice of bin size or smoothing bandwidth will determine how well the plot represents the underlying bivariate distribution. The same parameters apply, but they can be tuned for each variable by passing a pair of values: sns.displot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", binwidth=(2, .5)) To aid interpretation of the heatmap, add a colorbar to show the mapping between counts and color intensity: sns.displot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", binwidth=(2, .5), cbar=True) The meaning of the bivariate density contours is less straightforward. Because the density is not directly interpretable, the contours are drawn at iso-proportions of the density, meaning that each curve shows a level set such that some proportion p of the density lies below it. The p values are evenly spaced, with the lowest level contolled by the thresh parameter and the number controlled", "prev_chunk_id": "chunk_83", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_85", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Visualizing bivariate distributions#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Visualizing bivariate distributions#", "content": "by levels: sns.displot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", kind=\"kde\", thresh=.2, levels=4) The levels parameter also accepts a list of values, for more control: sns.displot(penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", kind=\"kde\", levels=[.01, .05, .1, .8]) The bivariate histogram allows one or both variables to be discrete. Plotting one discrete and one continuous variable offers another way to compare conditional univariate distributions: sns.displot(diamonds, x=\"price\", y=\"clarity\", log_scale=(True, False)) In contrast, plotting two discrete variables is an easy to way show the cross-tabulation of the observations: sns.displot(diamonds, x=\"color\", y=\"clarity\")", "prev_chunk_id": "chunk_84", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_86", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Distribution visualization in other settings#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Distribution visualization in other settings#", "content": "Distribution visualization in other settings# Several other figure-level plotting functions in seaborn make use of the histplot() and kdeplot() functions.", "prev_chunk_id": "chunk_85", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_87", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Plotting joint and marginal distributions#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Plotting joint and marginal distributions#", "content": "Plotting joint and marginal distributions# The first is jointplot(), which augments a bivariate relational or distribution plot with the marginal distributions of the two variables. By default, jointplot() represents the bivariate distribution using scatterplot() and the marginal distributions using histplot(): sns.jointplot(data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\") Similar to displot(), setting a different kind=\"kde\" in jointplot() will change both the joint and marginal plots the use kdeplot(): sns.jointplot( data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\", kind=\"kde\" ) jointplot() is a convenient interface to the JointGrid class, which offeres more flexibility when used directly: g = sns.JointGrid(data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\") g.plot_joint(sns.histplot) g.plot_marginals(sns.boxplot) A less-obtrusive way to show marginal distributions uses a “rug” plot, which adds a small tick on the edge of the plot to represent each individual observation. This is built into displot(): sns.displot( penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\", kind=\"kde\", rug=True ) And the axes-level rugplot() function can be used to add rugs on the side of any other kind of plot: sns.relplot(data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\") sns.rugplot(data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\")", "prev_chunk_id": "chunk_86", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_88", "url": "https://seaborn.pydata.org/tutorial/distributions.html", "title": "Plotting many distributions#", "page_title": "Visualizing distributions of data — seaborn 0.13.2 documentation", "breadcrumbs": "Plotting many distributions#", "content": "Plotting many distributions# The pairplot() function offers a similar blend of joint and marginal distributions. Rather than focusing on a single relationship, however, pairplot() uses a “small-multiple” approach to visualize the univariate distribution of all variables in a dataset along with all of their pairwise relationships: sns.pairplot(penguins) As with jointplot()/JointGrid, using the underlying PairGrid directly will afford more flexibility with only a bit more typing: g = sns.PairGrid(penguins) g.map_upper(sns.histplot) g.map_lower(sns.kdeplot, fill=True) g.map_diag(sns.histplot, kde=True)", "prev_chunk_id": "chunk_87", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_89", "url": "https://seaborn.pydata.org/tutorial/categorical.html", "title": "Visualizing categorical data#", "page_title": "Visualizing categorical data — seaborn 0.13.2 documentation", "breadcrumbs": "Visualizing categorical data#", "content": "Visualizing categorical data# In the relational plot tutorial we saw how to use different visual representations to show the relationship between multiple variables in a dataset. In the examples, we focused on cases where the main relationship was between two numerical variables. If one of the main variables is “categorical” (divided into discrete groups) it may be helpful to use a more specialized approach to visualization. In seaborn, there are several different ways to visualize a relationship involving categorical data. Similar to the relationship between relplot() and either scatterplot() or lineplot(), there are two ways to make these plots. There are a number of axes-level functions for plotting categorical data in different ways and a figure-level interface, catplot(), that gives unified higher-level access to them. It’s helpful to think of the different categorical plot kinds as belonging to three different families, which we’ll discuss in detail below. They are: Categorical scatterplots: - stripplot()(withkind=\"strip\"; the default) - swarmplot()(withkind=\"swarm\") Categorical distribution plots: - boxplot()(withkind=\"box\") - violinplot()(withkind=\"violin\") - boxenplot()(withkind=\"boxen\") Categorical estimate plots: - pointplot()(withkind=\"point\") - barplot()(withkind=\"bar\") - countplot()(withkind=\"count\") These families represent the data using different levels of granularity. When deciding which to use, you’ll have to think about the question that you want to answer. The unified API makes it easy to switch between different kinds and see your data from several perspectives. In this tutorial, we’ll mostly focus on the figure-level interface, catplot(). Remember that this function is a higher-level interface each of the functions above, so we’ll reference them when we show each kind of plot, keeping the more verbose kind-specific API documentation at hand.", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_90", "url": "https://seaborn.pydata.org/tutorial/categorical.html", "title": "Categorical scatterplots#", "page_title": "Visualizing categorical data — seaborn 0.13.2 documentation", "breadcrumbs": "Categorical scatterplots#", "content": "Categorical scatterplots# The default representation of the data in catplot() uses a scatterplot. There are actually two different categorical scatter plots in seaborn. They take different approaches to resolving the main challenge in representing categorical data with a scatter plot, which is that all of the points belonging to one category would fall on the same position along the axis corresponding to the categorical variable. The approach used by stripplot(), which is the default “kind” in catplot() is to adjust the positions of points on the categorical axis with a small amount of random “jitter”: tips = sns.load_dataset(\"tips\") sns.catplot(data=tips, x=\"day\", y=\"total_bill\")", "prev_chunk_id": "chunk_89", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_91", "url": "https://seaborn.pydata.org/tutorial/categorical.html", "title": "Comparing distributions#", "page_title": "Visualizing categorical data — seaborn 0.13.2 documentation", "breadcrumbs": "Comparing distributions#", "content": "Comparing distributions# As the size of the dataset grows, categorical scatter plots become limited in the information they can provide about the distribution of values within each category. When this happens, there are several approaches for summarizing the distributional information in ways that facilitate easy comparisons across the category levels.", "prev_chunk_id": "chunk_90", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_92", "url": "https://seaborn.pydata.org/tutorial/categorical.html", "title": "Boxplots#", "page_title": "Visualizing categorical data — seaborn 0.13.2 documentation", "breadcrumbs": "Boxplots#", "content": "Boxplots# The first is the familiar boxplot(). This kind of plot shows the three quartile values of the distribution along with extreme values. The “whiskers” extend to points that lie within 1.5 IQRs of the lower and upper quartile, and then observations that fall outside this range are displayed independently. This means that each value in the boxplot corresponds to an actual observation in the data. sns.catplot(data=tips, x=\"day\", y=\"total_bill\", kind=\"box\") When adding a hue semantic, the box for each level of the semantic variable is made narrower and shifted along the categorical axis: sns.catplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"smoker\", kind=\"box\") This behavior is called “dodging”, and it is controlled by the dodge parameter. By default (as of v0.13.0), elements dodge only if they would otherwise overlap: tips[\"weekend\"] = tips[\"day\"].isin([\"Sat\", \"Sun\"]) sns.catplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"weekend\", kind=\"box\") A related function, boxenplot(), draws a plot that is similar to a box plot but optimized for showing more information about the shape of the distribution. It is best suited for larger datasets: diamonds = sns.load_dataset(\"diamonds\") sns.catplot( data=diamonds.sort_values(\"color\"), x=\"color\", y=\"price\", kind=\"boxen\", )", "prev_chunk_id": "chunk_91", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_93", "url": "https://seaborn.pydata.org/tutorial/categorical.html", "title": "Violinplots#", "page_title": "Visualizing categorical data — seaborn 0.13.2 documentation", "breadcrumbs": "Violinplots#", "content": "Violinplots# A different approach is a violinplot(), which combines a boxplot with the kernel density estimation procedure described in the distributions tutorial: sns.catplot( data=tips, x=\"total_bill\", y=\"day\", hue=\"sex\", kind=\"violin\", ) This approach uses the kernel density estimate to provide a richer description of the distribution of values. Additionally, the quartile and whisker values from the boxplot are shown inside the violin. The downside is that, because the violinplot uses a KDE, there are some other parameters that may need tweaking, adding some complexity relative to the straightforward boxplot: sns.catplot( data=tips, x=\"total_bill\", y=\"day\", hue=\"sex\", kind=\"violin\", bw_adjust=.5, cut=0, ) It’s also possible to “split” the violins, which can allow for a more efficient use of space: sns.catplot( data=tips, x=\"day\", y=\"total_bill\", hue=\"sex\", kind=\"violin\", split=True, ) Finally, there are several options for the plot that is drawn on the interior of the violins, including ways to show each individual observation instead of the summary boxplot values: sns.catplot( data=tips, x=\"day\", y=\"total_bill\", hue=\"sex\", kind=\"violin\", inner=\"stick\", split=True, palette=\"pastel\", ) It can also be useful to combine swarmplot() or stripplot() with a box plot or violin plot to show each observation along with a summary of the distribution: g = sns.catplot(data=tips, x=\"day\", y=\"total_bill\", kind=\"violin\", inner=None) sns.swarmplot(data=tips, x=\"day\", y=\"total_bill\", color=\"k\", size=3, ax=g.ax)", "prev_chunk_id": "chunk_92", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_94", "url": "https://seaborn.pydata.org/tutorial/categorical.html", "title": "Estimating central tendency#", "page_title": "Visualizing categorical data — seaborn 0.13.2 documentation", "breadcrumbs": "Estimating central tendency#", "content": "Estimating central tendency# For other applications, rather than showing the distribution within each category, you might want to show an estimate of the central tendency of the values. Seaborn has two main ways to show this information. Importantly, the basic API for these functions is identical to that for the ones discussed above.", "prev_chunk_id": "chunk_93", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_95", "url": "https://seaborn.pydata.org/tutorial/categorical.html", "title": "Bar plots#", "page_title": "Visualizing categorical data — seaborn 0.13.2 documentation", "breadcrumbs": "Bar plots#", "content": "Bar plots# A familiar style of plot that accomplishes this goal is a bar plot. In seaborn, the barplot() function operates on a full dataset and applies a function to obtain the estimate (taking the mean by default). When there are multiple observations in each category, it also uses bootstrapping to compute a confidence interval around the estimate, which is plotted using error bars: titanic = sns.load_dataset(\"titanic\") sns.catplot(data=titanic, x=\"sex\", y=\"survived\", hue=\"class\", kind=\"bar\") The default error bars show 95% confidence intervals, but (starting in v0.12), it is possible to select from a number of other representations: sns.catplot(data=titanic, x=\"age\", y=\"deck\", errorbar=(\"pi\", 95), kind=\"bar\") A special case for the bar plot is when you want to show the number of observations in each category rather than computing a statistic for a second variable. This is similar to a histogram over a categorical, rather than quantitative, variable. In seaborn, it’s easy to do so with the countplot() function: sns.catplot(data=titanic, x=\"deck\", kind=\"count\") Both barplot() and countplot() can be invoked with all of the options discussed above, along with others that are demonstrated in the detailed documentation for each function: sns.catplot( data=titanic, y=\"deck\", hue=\"class\", kind=\"count\", palette=\"pastel\", edgecolor=\".6\", )", "prev_chunk_id": "chunk_94", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_96", "url": "https://seaborn.pydata.org/tutorial/categorical.html", "title": "Point plots#", "page_title": "Visualizing categorical data — seaborn 0.13.2 documentation", "breadcrumbs": "Point plots#", "content": "Point plots# An alternative style for visualizing the same information is offered by the pointplot() function. This function also encodes the value of the estimate with height on the other axis, but rather than showing a full bar, it plots the point estimate and confidence interval. Additionally, pointplot() connects points from the same hue category. This makes it easy to see how the main relationship is changing as a function of the hue semantic, because your eyes are quite good at picking up on differences of slopes: sns.catplot(data=titanic, x=\"sex\", y=\"survived\", hue=\"class\", kind=\"point\") While the categorical functions lack the style semantic of the relational functions, it can still be a good idea to vary the marker and/or linestyle along with the hue to make figures that are maximally accessible and reproduce well in black and white: sns.catplot( data=titanic, x=\"class\", y=\"survived\", hue=\"sex\", palette={\"male\": \"g\", \"female\": \"m\"}, markers=[\"^\", \"o\"], linestyles=[\"-\", \"--\"], kind=\"point\" )", "prev_chunk_id": "chunk_95", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_97", "url": "https://seaborn.pydata.org/tutorial/categorical.html", "title": "Showing additional dimensions#", "page_title": "Visualizing categorical data — seaborn 0.13.2 documentation", "breadcrumbs": "Showing additional dimensions#", "content": "Showing additional dimensions# Just like relplot(), the fact that catplot() is built on a FacetGrid means that it is easy to add faceting variables to visualize higher-dimensional relationships: sns.catplot( data=tips, x=\"day\", y=\"total_bill\", hue=\"smoker\", kind=\"swarm\", col=\"time\", aspect=.7, ) For further customization of the plot, you can use the methods on the FacetGrid object that it returns: g = sns.catplot( data=titanic, x=\"fare\", y=\"embark_town\", row=\"class\", kind=\"box\", orient=\"h\", sharex=False, margin_titles=True, height=1.5, aspect=4, ) g.set(xlabel=\"Fare\", ylabel=\"\") g.set_titles(row_template=\"{row_name} class\") for ax in g.axes.flat: ax.xaxis.set_major_formatter('${x:.0f}')", "prev_chunk_id": "chunk_96", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_98", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Statistical estimation and error bars#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Statistical estimation and error bars#", "content": "Statistical estimation and error bars# Data visualization sometimes involves a step of aggregation or estimation, where multiple data points are reduced to a summary statistic such as the mean or median. When showing a summary statistic, it is usually appropriate to add error bars, which provide a visual cue about how well the summary represents the underlying data points. Several seaborn functions will automatically calculate both summary statistics and the error bars when given a full dataset. This chapter explains how you can control what the error bars show and why you might choose each of the options that seaborn affords. The error bars around an estimate of central tendency can show one of two general things: either the range of uncertainty about the estimate or the spread of the underlying data around it. These measures are related: given the same sample size, estimates will be more uncertain when data has a broader spread. But uncertainty will decrease as sample sizes grow, whereas spread will not. In seaborn, there are two approaches for constructing each kind of error bar. One approach is parametric, using a formula that relies on assumptions about the shape of the distribution. The other approach is nonparametric, using only the data that you provide. Your choice is made with the errorbar parameter, which exists for each function that does estimation as part of plotting. This parameter accepts the name of the method to use and, optionally, a parameter that controls the size of the interval. The choices can be defined in a 2D taxonomy that depends on what is shown and how it is constructed:", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_99", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Measures of data spread#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Measures of data spread#", "content": "Measures of data spread# Error bars that represent data spread present a compact display of the distribution, using three numbers where boxplot() would use 5 or more and violinplot() would use a complicated algorithm.", "prev_chunk_id": "chunk_98", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_100", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Standard deviation error bars#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Standard deviation error bars#", "content": "Standard deviation error bars# Standard deviation error bars are the simplest to explain, because the standard deviation is a familiar statistic. It is the average distance from each data point to the sample mean. By default, errorbar=\"sd\" will draw error bars at +/- 1 sd around the estimate, but the range can be increased by passing a scaling size parameter. Note that, assuming normally-distributed data, ~68% of the data will lie within one standard deviation, ~95% will lie within two, and ~99.7% will lie within three: plot_errorbars(\"sd\")", "prev_chunk_id": "chunk_99", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_101", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Percentile interval error bars#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Percentile interval error bars#", "content": "Percentile interval error bars# Percentile intervals also represent the range where some amount of the data fall, but they do so by computing those percentiles directly from your sample. By default, errorbar=\"pi\" will show a 95% interval, ranging from the 2.5 to the 97.5 percentiles. You can choose a different range by passing a size parameter, e.g., to show the inter-quartile range: plot_errorbars((\"pi\", 50)) The standard deviation error bars will always be symmetrical around the estimate. This can be a problem when the data are skewed, especially if there are natural bounds (e.g., if the data represent a quantity that can only be positive). In some cases, standard deviation error bars may extend to “impossible” values. The nonparametric approach does not have this problem, because it can account for asymmetrical spread and will never extend beyond the range of the data.", "prev_chunk_id": "chunk_100", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_102", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Measures of estimate uncertainty#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Measures of estimate uncertainty#", "content": "Measures of estimate uncertainty# If your data are a random sample from a larger population, then the mean (or other estimate) will be an imperfect measure of the true population average. Error bars that show estimate uncertainty try to represent the range of likely values for the true parameter.", "prev_chunk_id": "chunk_101", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_103", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Standard error bars#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Standard error bars#", "content": "Standard error bars# The standard error statistic is related to the standard deviation: in fact it is just the standard deviation divided by the square root of the sample size. The default, with errorbar=\"se\", draws an interval +/-1 standard error from the mean: plot_errorbars(\"se\")", "prev_chunk_id": "chunk_102", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_104", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Confidence interval error bars#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Confidence interval error bars#", "content": "Confidence interval error bars# The nonparametric approach to representing uncertainty uses bootstrapping: a procedure where the dataset is randomly resampled with replacement a number of times, and the estimate is recalculated from each resample. This procedure creates a distribution of statistics approximating the distribution of values that you could have gotten for your estimate if you had a different sample. The confidence interval is constructed by taking a percentile interval of the bootstrap distribution. By default errorbar=\"ci\" draws a 95% confidence interval: plot_errorbars(\"ci\") The seaborn terminology is somewhat specific, because a confidence interval in statistics can be parametric or nonparametric. To draw a parametric confidence interval, you scale the standard error, using a formula similar to the one mentioned above. For example, an approximate 95% confidence interval can be constructed by taking the mean +/- two standard errors: plot_errorbars((\"se\", 2)) The nonparametric bootstrap has advantages similar to those of the percentile interval: it will naturally adapt to skewed and bounded data in a way that a standard error interval cannot. It is also more general. While the standard error formula is specific to the mean, error bars can be computed using the bootstrap for any estimator: plot_errorbars(\"ci\", estimator=\"median\") Bootstrapping involves randomness, and the error bars will appear slightly different each time you run the code that creates them. A few parameters control this. One sets the number of iterations (n_boot): with more iterations, the resulting intervals will be more stable. The other sets the seed for the random number generator, which will ensure identical results: plot_errorbars(\"ci\", n_boot=5000, seed=10) Because of its iterative process, bootstrap intervals can be expensive to compute, especially for large datasets. But because uncertainty decreases with sample size, it may be more informative in that case to use an error bar that represents data spread.", "prev_chunk_id": "chunk_103", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_105", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Custom error bars#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Custom error bars#", "content": "Custom error bars# If these recipes are not sufficient, it is also possible to pass a generic function to the errorbar parameter. This function should take a vector and produce a pair of values representing the minimum and maximum points of the interval: plot_errorbars(lambda x: (x.min(), x.max())) (In practice, you could show the full range of the data with errorbar=(\"pi\", 100) rather than the custom function shown above). Note that seaborn functions cannot currently draw error bars from values that have been calculated externally, although matplotlib functions can be used to add such error bars to seaborn plots.", "prev_chunk_id": "chunk_104", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_106", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Error bars on regression fits#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Error bars on regression fits#", "content": "Error bars on regression fits# The preceding discussion has focused on error bars shown around parameter estimates for aggregate data. Error bars also arise in seaborn when estimating regression models to visualize relationships. Here, the error bars will be represented by a “band” around the regression line: x = np.random.normal(0, 1, 50) y = x * 2 + np.random.normal(0, 2, size=x.size) sns.regplot(x=x, y=y) Currently, the error bars on a regression estimate are less flexible, only showing a confidence interval with a size set through ci=. This may change in the future.", "prev_chunk_id": "chunk_105", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_107", "url": "https://seaborn.pydata.org/tutorial/error_bars.html", "title": "Are error bars enough?#", "page_title": "Statistical estimation and error bars — seaborn 0.13.2 documentation", "breadcrumbs": "Are error bars enough?#", "content": "Are error bars enough?# You should always ask yourself whether it’s best to use a plot that displays only a summary statistic and error bar. In many cases, it isn’t. If you are interested in questions about summaries (such as whether the mean value differs between groups or increases over time), aggregation reduces the complexity of the plot and makes those inferences easier. But in doing so, it obscures valuable information about the underlying data points, such as the shape of the distributions and the presence of outliers. When analyzing your own data, don’t be satisfied with summary statistics. Always look at the underlying distributions too. Sometimes, it can be helpful to combine both perspectives into the same figure. Many seaborn functions can help with this task, especially those discussed in the categorical tutorial.", "prev_chunk_id": "chunk_106", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_108", "url": "https://seaborn.pydata.org/tutorial/regression.html", "title": "Estimating regression fits#", "page_title": "Estimating regression fits — seaborn 0.13.2 documentation", "breadcrumbs": "Estimating regression fits#", "content": "Estimating regression fits# Many datasets contain multiple quantitative variables, and the goal of an analysis is often to relate those variables to each other. We previously discussed functions that can accomplish this by showing the joint distribution of two variables. It can be very helpful, though, to use statistical models to estimate a simple relationship between two noisy sets of observations. The functions discussed in this chapter will do so through the common framework of linear regression. In the spirit of Tukey, the regression plots in seaborn are primarily intended to add a visual guide that helps to emphasize patterns in a dataset during exploratory data analyses. That is to say that seaborn is not itself a package for statistical analysis. To obtain quantitative measures related to the fit of regression models, you should use statsmodels. The goal of seaborn, however, is to make exploring a dataset through visualization quick and easy, as doing so is just as (if not more) important than exploring a dataset through tables of statistics.", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_109", "url": "https://seaborn.pydata.org/tutorial/regression.html", "title": "Functions for drawing linear regression models#", "page_title": "Estimating regression fits — seaborn 0.13.2 documentation", "breadcrumbs": "Functions for drawing linear regression models#", "content": "Functions for drawing linear regression models# The two functions that can be used to visualize a linear fit are regplot() and lmplot(). In the simplest invocation, both functions draw a scatterplot of two variables, x and y, and then fit the regression model y ~ x and plot the resulting regression line and a 95% confidence interval for that regression: tips = sns.load_dataset(\"tips\") sns.regplot(x=\"total_bill\", y=\"tip\", data=tips);", "prev_chunk_id": "chunk_108", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_110", "url": "https://seaborn.pydata.org/tutorial/regression.html", "title": "Fitting different kinds of models#", "page_title": "Estimating regression fits — seaborn 0.13.2 documentation", "breadcrumbs": "Fitting different kinds of models#", "content": "Fitting different kinds of models# The simple linear regression model used above is very simple to fit, however, it is not appropriate for some kinds of datasets. The Anscombe’s quartet dataset shows a few examples where simple linear regression provides an identical estimate of a relationship where simple visual inspection clearly shows differences. For example, in the first case, the linear regression is a good model: anscombe = sns.load_dataset(\"anscombe\") sns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'I'\"), ci=None, scatter_kws={\"s\": 80}); The linear relationship in the second dataset is the same, but the plot clearly shows that this is not a good model: sns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'II'\"), ci=None, scatter_kws={\"s\": 80}); In the presence of these kind of higher-order relationships, lmplot() and regplot() can fit a polynomial regression model to explore simple kinds of nonlinear trends in the dataset: sns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'II'\"), order=2, ci=None, scatter_kws={\"s\": 80}); A different problem is posed by “outlier” observations that deviate for some reason other than the main relationship under study: sns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'III'\"), ci=None, scatter_kws={\"s\": 80}); In the presence of outliers, it can be useful to fit a robust regression, which uses a different loss function to downweight relatively large residuals: sns.lmplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'III'\"), robust=True, ci=None, scatter_kws={\"s\": 80}); When the y variable is binary, simple linear regression also “works” but provides implausible predictions: tips[\"big_tip\"] = (tips.tip / tips.total_bill) > .15 sns.lmplot(x=\"total_bill\", y=\"big_tip\", data=tips, y_jitter=.03); The solution in this case is to fit a logistic regression, such that the regression line shows the estimated probability of y = 1 for a given value of x: sns.lmplot(x=\"total_bill\", y=\"big_tip\", data=tips, logistic=True, y_jitter=.03); Note that the logistic regression estimate is considerably more computationally intensive (this is true of robust regression as well). As the confidence interval around the regression line is computed using a bootstrap procedure,", "prev_chunk_id": "chunk_109", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_111", "url": "https://seaborn.pydata.org/tutorial/regression.html", "title": "Fitting different kinds of models#", "page_title": "Estimating regression fits — seaborn 0.13.2 documentation", "breadcrumbs": "Fitting different kinds of models#", "content": "you may wish to turn this off for faster iteration (using ci=None). An altogether different approach is to fit a nonparametric regression using a lowess smoother. This approach has the fewest assumptions, although it is computationally intensive and so currently confidence intervals are not computed at all: sns.lmplot(x=\"total_bill\", y=\"tip\", data=tips, lowess=True, line_kws={\"color\": \"C1\"}); The residplot() function can be a useful tool for checking whether the simple regression model is appropriate for a dataset. It fits and removes a simple linear regression and then plots the residual values for each observation. Ideally, these values should be randomly scattered around y = 0: sns.residplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'I'\"), scatter_kws={\"s\": 80}); If there is structure in the residuals, it suggests that simple linear regression is not appropriate: sns.residplot(x=\"x\", y=\"y\", data=anscombe.query(\"dataset == 'II'\"), scatter_kws={\"s\": 80});", "prev_chunk_id": "chunk_110", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_112", "url": "https://seaborn.pydata.org/tutorial/regression.html", "title": "Conditioning on other variables#", "page_title": "Estimating regression fits — seaborn 0.13.2 documentation", "breadcrumbs": "Conditioning on other variables#", "content": "Conditioning on other variables# The plots above show many ways to explore the relationship between a pair of variables. Often, however, a more interesting question is “how does the relationship between these two variables change as a function of a third variable?” This is where the main differences between regplot() and lmplot() appear. While regplot() always shows a single relationship, lmplot() combines regplot() with FacetGrid to show multiple fits using hue mapping or faceting. The best way to separate out a relationship is to plot both levels on the same axes and to use color to distinguish them: sns.lmplot(x=\"total_bill\", y=\"tip\", hue=\"smoker\", data=tips); Unlike relplot(), it’s not possible to map a distinct variable to the style properties of the scatter plot, but you can redundantly code the hue variable with marker shape: sns.lmplot(x=\"total_bill\", y=\"tip\", hue=\"smoker\", data=tips, markers=[\"o\", \"x\"], palette=\"Set1\"); To add another variable, you can draw multiple “facets” with each level of the variable appearing in the rows or columns of the grid: sns.lmplot(x=\"total_bill\", y=\"tip\", hue=\"smoker\", col=\"time\", data=tips); sns.lmplot(x=\"total_bill\", y=\"tip\", hue=\"smoker\", col=\"time\", row=\"sex\", data=tips, height=3);", "prev_chunk_id": "chunk_111", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_113", "url": "https://seaborn.pydata.org/tutorial/regression.html", "title": "Plotting a regression in other contexts#", "page_title": "Estimating regression fits — seaborn 0.13.2 documentation", "breadcrumbs": "Plotting a regression in other contexts#", "content": "Plotting a regression in other contexts# A few other seaborn functions use regplot() in the context of a larger, more complex plot. The first is the jointplot() function that we introduced in the distributions tutorial. In addition to the plot styles previously discussed, jointplot() can use regplot() to show the linear regression fit on the joint axes by passing kind=\"reg\": sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\"); Using the pairplot() function with kind=\"reg\" combines regplot() and PairGrid to show the linear relationship between variables in a dataset. Take care to note how this is different from lmplot(). In the figure below, the two axes don’t show the same relationship conditioned on two levels of a third variable; rather, PairGrid() is used to show multiple relationships between different pairings of the variables in a dataset: sns.pairplot(tips, x_vars=[\"total_bill\", \"size\"], y_vars=[\"tip\"], height=5, aspect=.8, kind=\"reg\"); Conditioning on an additional categorical variable is built into both of these functions using the hue parameter: sns.pairplot(tips, x_vars=[\"total_bill\", \"size\"], y_vars=[\"tip\"], hue=\"smoker\", height=5, aspect=.8, kind=\"reg\");", "prev_chunk_id": "chunk_112", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_114", "url": "https://seaborn.pydata.org/tutorial/axis_grids.html", "title": "Building structured multi-plot grids#", "page_title": "Building structured multi-plot grids — seaborn 0.13.2 documentation", "breadcrumbs": "Building structured multi-plot grids#", "content": "Building structured multi-plot grids# When exploring multi-dimensional data, a useful approach is to draw multiple instances of the same plot on different subsets of your dataset. This technique is sometimes called either “lattice” or “trellis” plotting, and it is related to the idea of “small multiples”. It allows a viewer to quickly extract a large amount of information about a complex dataset. Matplotlib offers good support for making figures with multiple axes; seaborn builds on top of this to directly link the structure of the plot to the structure of your dataset. The figure-level functions are built on top of the objects discussed in this chapter of the tutorial. In most cases, you will want to work with those functions. They take care of some important bookkeeping that synchronizes the multiple plots in each grid. This chapter explains how the underlying objects work, which may be useful for advanced applications.", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_115", "url": "https://seaborn.pydata.org/tutorial/axis_grids.html", "title": "Conditional small multiples#", "page_title": "Building structured multi-plot grids — seaborn 0.13.2 documentation", "breadcrumbs": "Conditional small multiples#", "content": "Conditional small multiples# The FacetGrid class is useful when you want to visualize the distribution of a variable or the relationship between multiple variables separately within subsets of your dataset. A FacetGrid can be drawn with up to three dimensions: row, col, and hue. The first two have obvious correspondence with the resulting array of axes; think of the hue variable as a third dimension along a depth axis, where different levels are plotted with different colors. Each of relplot(), displot(), catplot(), and lmplot() use this object internally, and they return the object when they are finished so that it can be used for further tweaking. The class is used by initializing a FacetGrid object with a dataframe and the names of the variables that will form the row, column, or hue dimensions of the grid. These variables should be categorical or discrete, and then the data at each level of the variable will be used for a facet along that axis. For example, say we wanted to examine differences between lunch and dinner in the tips dataset: tips = sns.load_dataset(\"tips\") g = sns.FacetGrid(tips, col=\"time\")", "prev_chunk_id": "chunk_114", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_116", "url": "https://seaborn.pydata.org/tutorial/axis_grids.html", "title": "Using custom functions#", "page_title": "Building structured multi-plot grids — seaborn 0.13.2 documentation", "breadcrumbs": "Using custom functions#", "content": "Using custom functions# You’re not limited to existing matplotlib and seaborn functions when using FacetGrid. However, to work properly, any function you use must follow a few rules: - It must plot onto the “currently active” matplotlibAxes. This will be true of functions in thematplotlib.pyplotnamespace, and you can callmatplotlib.pyplot.gca()to get a reference to the currentAxesif you want to work directly with its methods. - It must accept the data that it plots in positional arguments. Internally,FacetGridwill pass aSeriesof data for each of the named positional arguments passed toFacetGrid.map(). - It must be able to acceptcolorandlabelkeyword arguments, and, ideally, it will do something useful with them. In most cases, it’s easiest to catch a generic dictionary of**kwargsand pass it along to the underlying plotting function. Let’s look at minimal example of a function you can plot with. This function will just take a single vector of data for each facet: from scipy import stats def quantile_plot(x, **kwargs): quantiles, xr = stats.probplot(x, fit=False) plt.scatter(xr, quantiles, **kwargs) g = sns.FacetGrid(tips, col=\"sex\", height=4) g.map(quantile_plot, \"total_bill\") If we want to make a bivariate plot, you should write the function so that it accepts the x-axis variable first and the y-axis variable second: def qqplot(x, y, **kwargs): _, xr = stats.probplot(x, fit=False) _, yr = stats.probplot(y, fit=False) plt.scatter(xr, yr, **kwargs) g = sns.FacetGrid(tips, col=\"smoker\", height=4) g.map(qqplot, \"total_bill\", \"tip\") Because matplotlib.pyplot.scatter() accepts color and label keyword arguments and does the right thing with them, we can add a hue facet without any difficulty: g = sns.FacetGrid(tips, hue=\"time\", col=\"sex\", height=4) g.map(qqplot, \"total_bill\", \"tip\") g.add_legend() Sometimes, though, you’ll want to map a function that doesn’t work the way you expect with the color and label keyword arguments. In this case, you’ll want to explicitly catch them and handle them in the logic of your custom function. For example, this", "prev_chunk_id": "chunk_115", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_117", "url": "https://seaborn.pydata.org/tutorial/axis_grids.html", "title": "Using custom functions#", "page_title": "Building structured multi-plot grids — seaborn 0.13.2 documentation", "breadcrumbs": "Using custom functions#", "content": "approach will allow use to map matplotlib.pyplot.hexbin(), which otherwise does not play well with the FacetGrid API: def hexbin(x, y, color, **kwargs): cmap = sns.light_palette(color, as_cmap=True) plt.hexbin(x, y, gridsize=15, cmap=cmap, **kwargs) with sns.axes_style(\"dark\"): g = sns.FacetGrid(tips, hue=\"time\", col=\"time\", height=4) g.map(hexbin, \"total_bill\", \"tip\", extent=[0, 50, 0, 10]);", "prev_chunk_id": "chunk_116", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_118", "url": "https://seaborn.pydata.org/tutorial/axis_grids.html", "title": "Plotting pairwise data relationships#", "page_title": "Building structured multi-plot grids — seaborn 0.13.2 documentation", "breadcrumbs": "Plotting pairwise data relationships#", "content": "Plotting pairwise data relationships# PairGrid also allows you to quickly draw a grid of small subplots using the same plot type to visualize data in each. In a PairGrid, each row and column is assigned to a different variable, so the resulting plot shows each pairwise relationship in the dataset. This style of plot is sometimes called a “scatterplot matrix”, as this is the most common way to show each relationship, but PairGrid is not limited to scatterplots. It’s important to understand the differences between a FacetGrid and a PairGrid. In the former, each facet shows the same relationship conditioned on different levels of other variables. In the latter, each plot shows a different relationship (although the upper and lower triangles will have mirrored plots). Using PairGrid can give you a very quick, very high-level summary of interesting relationships in your dataset. The basic usage of the class is very similar to FacetGrid. First you initialize the grid, then you pass plotting function to a map method and it will be called on each subplot. There is also a companion function, pairplot() that trades off some flexibility for faster plotting. iris = sns.load_dataset(\"iris\") g = sns.PairGrid(iris) g.map(sns.scatterplot) It’s possible to plot a different function on the diagonal to show the univariate distribution of the variable in each column. Note that the axis ticks won’t correspond to the count or density axis of this plot, though. g = sns.PairGrid(iris) g.map_diag(sns.histplot) g.map_offdiag(sns.scatterplot) A very common way to use this plot colors the observations by a separate categorical variable. For example, the iris dataset has four measurements for each of three different species of iris flowers so you can see how they differ. g = sns.PairGrid(iris, hue=\"species\") g.map_diag(sns.histplot) g.map_offdiag(sns.scatterplot) g.add_legend() By default every numeric column in the dataset is used, but you can", "prev_chunk_id": "chunk_117", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_119", "url": "https://seaborn.pydata.org/tutorial/axis_grids.html", "title": "Plotting pairwise data relationships#", "page_title": "Building structured multi-plot grids — seaborn 0.13.2 documentation", "breadcrumbs": "Plotting pairwise data relationships#", "content": "focus on particular relationships if you want. g = sns.PairGrid(iris, vars=[\"sepal_length\", \"sepal_width\"], hue=\"species\") g.map(sns.scatterplot) It’s also possible to use a different function in the upper and lower triangles to emphasize different aspects of the relationship. g = sns.PairGrid(iris) g.map_upper(sns.scatterplot) g.map_lower(sns.kdeplot) g.map_diag(sns.kdeplot, lw=3, legend=False) The square grid with identity relationships on the diagonal is actually just a special case, and you can plot with different variables in the rows and columns. g = sns.PairGrid(tips, y_vars=[\"tip\"], x_vars=[\"total_bill\", \"size\"], height=4) g.map(sns.regplot, color=\".3\") g.set(ylim=(-1, 11), yticks=[0, 5, 10]) Of course, the aesthetic attributes are configurable. For instance, you can use a different palette (say, to show an ordering of the hue variable) and pass keyword arguments into the plotting functions. g = sns.PairGrid(tips, hue=\"size\", palette=\"GnBu_d\") g.map(plt.scatter, s=50, edgecolor=\"white\") g.add_legend() PairGrid is flexible, but to take a quick look at a dataset, it can be easier to use pairplot(). This function uses scatterplots and histograms by default, although a few other kinds will be added (currently, you can also plot regression plots on the off-diagonals and KDEs on the diagonal). sns.pairplot(iris, hue=\"species\", height=2.5) You can also control the aesthetics of the plot with keyword arguments, and it returns the PairGrid instance for further tweaking. g = sns.pairplot(iris, hue=\"species\", palette=\"Set2\", diag_kind=\"kde\", height=2.5)", "prev_chunk_id": "chunk_118", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_120", "url": "https://seaborn.pydata.org/tutorial/aesthetics.html", "title": "Controlling figure aesthetics#", "page_title": "Controlling figure aesthetics — seaborn 0.13.2 documentation", "breadcrumbs": "Controlling figure aesthetics#", "content": "Controlling figure aesthetics# Drawing attractive figures is important. When making figures for yourself, as you explore a dataset, it’s nice to have plots that are pleasant to look at. Visualizations are also central to communicating quantitative insights to an audience, and in that setting it’s even more necessary to have figures that catch the attention and draw a viewer in. Matplotlib is highly customizable, but it can be hard to know what settings to tweak to achieve an attractive plot. Seaborn comes with a number of customized themes and a high-level interface for controlling the look of matplotlib figures. import numpy as np import seaborn as sns import matplotlib.pyplot as plt Let’s define a simple function to plot some offset sine waves, which will help us see the different stylistic parameters we can tweak. def sinplot(n=10, flip=1): x = np.linspace(0, 14, 100) for i in range(1, n + 1): plt.plot(x, np.sin(x + i * .5) * (n + 2 - i) * flip) This is what the plot looks like with matplotlib defaults: sinplot()", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_121", "url": "https://seaborn.pydata.org/tutorial/aesthetics.html", "title": "Seaborn figure styles#", "page_title": "Controlling figure aesthetics — seaborn 0.13.2 documentation", "breadcrumbs": "Seaborn figure styles#", "content": "Seaborn figure styles# There are five preset seaborn themes: darkgrid, whitegrid, dark, white, and ticks. They are each suited to different applications and personal preferences. The default theme is darkgrid. As mentioned above, the grid helps the plot serve as a lookup table for quantitative information, and the white-on grey helps to keep the grid from competing with lines that represent data. The whitegrid theme is similar, but it is better suited to plots with heavy data elements: sns.set_style(\"whitegrid\") data = np.random.normal(size=(20, 6)) + np.arange(6) / 2 sns.boxplot(data=data); For many plots, (especially for settings like talks, where you primarily want to use figures to provide impressions of patterns in the data), the grid is less necessary. sns.set_style(\"dark\") sinplot() sns.set_style(\"white\") sinplot() Sometimes you might want to give a little extra structure to the plots, which is where ticks come in handy: sns.set_style(\"ticks\") sinplot()", "prev_chunk_id": "chunk_120", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_122", "url": "https://seaborn.pydata.org/tutorial/aesthetics.html", "title": "Removing axes spines#", "page_title": "Controlling figure aesthetics — seaborn 0.13.2 documentation", "breadcrumbs": "Removing axes spines#", "content": "Removing axes spines# Both the white and ticks styles can benefit from removing the top and right axes spines, which are not needed. The seaborn function despine() can be called to remove them: sinplot() sns.despine() Some plots benefit from offsetting the spines away from the data, which can also be done when calling despine(). When the ticks don’t cover the whole range of the axis, the trim parameter will limit the range of the surviving spines. f, ax = plt.subplots() sns.violinplot(data=data) sns.despine(offset=10, trim=True); You can also control which spines are removed with additional arguments to despine(): sns.set_style(\"whitegrid\") sns.boxplot(data=data, palette=\"deep\") sns.despine(left=True)", "prev_chunk_id": "chunk_121", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_123", "url": "https://seaborn.pydata.org/tutorial/aesthetics.html", "title": "Temporarily setting figure style#", "page_title": "Controlling figure aesthetics — seaborn 0.13.2 documentation", "breadcrumbs": "Temporarily setting figure style#", "content": "Temporarily setting figure style# Although it’s easy to switch back and forth, you can also use the axes_style() function in a with statement to temporarily set plot parameters. This also allows you to make figures with differently-styled axes: f = plt.figure(figsize=(6, 6)) gs = f.add_gridspec(2, 2) with sns.axes_style(\"darkgrid\"): ax = f.add_subplot(gs[0, 0]) sinplot(6) with sns.axes_style(\"white\"): ax = f.add_subplot(gs[0, 1]) sinplot(6) with sns.axes_style(\"ticks\"): ax = f.add_subplot(gs[1, 0]) sinplot(6) with sns.axes_style(\"whitegrid\"): ax = f.add_subplot(gs[1, 1]) sinplot(6) f.tight_layout()", "prev_chunk_id": "chunk_122", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_124", "url": "https://seaborn.pydata.org/tutorial/aesthetics.html", "title": "Overriding elements of the seaborn styles#", "page_title": "Controlling figure aesthetics — seaborn 0.13.2 documentation", "breadcrumbs": "Overriding elements of the seaborn styles#", "content": "Overriding elements of the seaborn styles# If you want to customize the seaborn styles, you can pass a dictionary of parameters to the rc argument of axes_style() and set_style(). Note that you can only override the parameters that are part of the style definition through this method. (However, the higher-level set_theme() function takes a dictionary of any matplotlib parameters). If you want to see what parameters are included, you can just call the function with no arguments, which will return the current settings: sns.axes_style() You can then set different versions of these parameters: sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"}) sinplot()", "prev_chunk_id": "chunk_123", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_125", "url": "https://seaborn.pydata.org/tutorial/aesthetics.html", "title": "Scaling plot elements#", "page_title": "Controlling figure aesthetics — seaborn 0.13.2 documentation", "breadcrumbs": "Scaling plot elements#", "content": "Scaling plot elements# A separate set of parameters control the scale of plot elements, which should let you use the same code to make plots that are suited for use in settings where larger or smaller plots are appropriate. First let’s reset the default parameters by calling set_theme(): sns.set_theme() The four preset contexts, in order of relative size, are paper, notebook, talk, and poster. The notebook style is the default, and was used in the plots above. sns.set_context(\"paper\") sinplot() sns.set_context(\"talk\") sinplot() sns.set_context(\"poster\") sinplot() Most of what you now know about the style functions should transfer to the context functions. You can call set_context() with one of these names to set the parameters, and you can override the parameters by providing a dictionary of parameter values. You can also independently scale the size of the font elements when changing the context. (This option is also available through the top-level set() function). sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5}) sinplot() Similarly, you can temporarily control the scale of figures nested under a with statement. Both the style and the context can be quickly configured with the set() function. This function also sets the default color palette, but that will be covered in more detail in the next section of the tutorial.", "prev_chunk_id": "chunk_124", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_126", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Choosing color palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Choosing color palettes#", "content": "Choosing color palettes# Seaborn makes it easy to use colors that are well-suited to the characteristics of your data and your visualization goals. This chapter discusses both the general principles that should guide your choices and the tools in seaborn that help you quickly find the best solution for a given application.", "prev_chunk_id": null, "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_127", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Components of color#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Components of color#", "content": "Components of color# Because of the way our eyes work, a particular color can be defined using three components. We usually program colors in a computer by specifying their RGB values, which set the intensity of the red, green, and blue channels in a display. But for analyzing the perceptual attributes of a color, it’s better to think in terms of hue, saturation, and luminance channels. Hue is the component that distinguishes “different colors” in a non-technical sense. It’s property of color that leads to first-order names like “red” and “blue”: Saturation (or chroma) is the colorfulness. Two colors with different hues will look more distinct when they have more saturation: And lightness corresponds to how much light is emitted (or reflected, for printed colors), ranging from black to white:", "prev_chunk_id": "chunk_126", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_128", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Vary hue to distinguish categories#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Vary hue to distinguish categories#", "content": "Vary hue to distinguish categories# When you want to represent multiple categories in a plot, you typically should vary the color of the elements. Consider this simple example: in which of these two plots is it easier to count the number of triangular points?", "prev_chunk_id": "chunk_127", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_129", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Vary luminance to represent numbers#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Vary luminance to represent numbers#", "content": "Vary luminance to represent numbers# On the other hand, hue variations are not well suited to representing numeric data. Consider this example, where we need colors to represent the counts in a bivariate histogram. On the left, we use a circular colormap, where gradual changes in the number of observation within each bin correspond to gradual changes in hue. On the right, we use a palette that uses brighter colors to represent bins with larger counts: With the hue-based palette, it’s quite difficult to ascertain the shape of the bivariate distribution. In contrast, the luminance palette makes it much more clear that there are two prominent peaks. Varying luminance helps you see structure in data, and changes in luminance are more intuitively processed as changes in importance. But the plot on the right does not use a grayscale colormap. Its colorfulness makes it more interesting, and the subtle hue variation increases the perceptual distance between two values. As a result, small differences slightly easier to resolve. These examples show that color palette choices are about more than aesthetics: the colors you choose can reveal patterns in your data if used effectively or hide them if used poorly. There is not one optimal palette, but there are palettes that are better or worse for particular datasets and visualization approaches. And aesthetics do matter: the more that people want to look at your figures, the greater the chance that they will learn something from them. This is true even when you are making plots for yourself. During exploratory data analysis, you may generate many similar figures. Varying the color palettes will add a sense of novelty, which keeps you engaged and prepared to notice interesting features of your data. So how can you choose color palettes that both represent your data well", "prev_chunk_id": "chunk_128", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_130", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Vary luminance to represent numbers#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Vary luminance to represent numbers#", "content": "and look attractive?", "prev_chunk_id": "chunk_129", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_131", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Tools for choosing color palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Tools for choosing color palettes#", "content": "Tools for choosing color palettes# The most important function for working with color palettes is, aptly, color_palette(). This function provides an interface to most of the possible ways that one can generate color palettes in seaborn. And it’s used internally by any function that has a palette argument. The primary argument to color_palette() is usually a string: either the name of a specific palette or the name of a family and additional arguments to select a specific member. In the latter case, color_palette() will delegate to more specific function, such as cubehelix_palette(). It’s also possible to pass a list of colors specified any way that matplotlib accepts (an RGB tuple, a hex code, or a name in the X11 table). The return value is an object that wraps a list of RGB tuples with a few useful methods, such as conversion to hex codes and a rich HTML representation. Calling color_palette() with no arguments will return the current default color palette that matplotlib (and most seaborn functions) will use if colors are not otherwise specified. This default palette can be set with the corresponding set_palette() function, which calls color_palette() internally and accepts the same arguments. To motivate the different options that color_palette() provides, it will be useful to introduce a classification scheme for color palettes. Broadly, palettes fall into one of three categories: - qualitative palettes, good for representing categorical data - sequential palettes, good for representing numeric data - diverging palettes, good for representing numeric data with a categorical boundary", "prev_chunk_id": "chunk_130", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_132", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Qualitative color palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Qualitative color palettes#", "content": "Qualitative color palettes# Qualitative palettes are well-suited to representing categorical data because most of their variation is in the hue component. The default color palette in seaborn is a qualitative palette with ten distinct hues: sns.color_palette() These colors have the same ordering as the default matplotlib color palette, \"tab10\", but they are a bit less intense. Compare: sns.color_palette(\"tab10\") Seaborn in fact has six variations of matplotlib’s palette, called deep, muted, pastel, bright, dark, and colorblind. These span a range of average luminance and saturation values: Many people find the moderated hues of the default \"deep\" palette to be aesthetically pleasing, but they are also less distinct. As a result, they may be more difficult to discriminate in some contexts, which is something to keep in mind when making publication graphics. This comparison can be helpful for estimating how the seaborn color palettes perform when simulating different forms of colorblindess.", "prev_chunk_id": "chunk_131", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_133", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Using circular color systems#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Using circular color systems#", "content": "Using circular color systems# When you have an arbitrary number of categories, the easiest approach to finding unique hues is to draw evenly-spaced colors in a circular color space (one where the hue changes while keeping the brightness and saturation constant). This is what most seaborn functions default to when they need to use more colors than are currently set in the default color cycle. The most common way to do this uses the hls color space, which is a simple transformation of RGB values. We saw this color palette before as a counterexample for how to plot a histogram: sns.color_palette(\"hls\", 8) Because of the way the human visual system works, colors that have the same luminance and saturation in terms of their RGB values won’t necessarily look equally intense To remedy this, seaborn provides an interface to the husl system (since renamed to HSLuv), which achieves less intensity variation as you rotate around the color wheel: sns.color_palette(\"husl\", 8) When seaborn needs a categorical palette with more colors than are available in the current default, it will use this approach.", "prev_chunk_id": "chunk_132", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_134", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Using categorical Color Brewer palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Using categorical Color Brewer palettes#", "content": "Using categorical Color Brewer palettes# Another source of visually pleasing categorical palettes comes from the Color Brewer tool (which also has sequential and diverging palettes, as we’ll see below). sns.color_palette(\"Set2\") Be aware that the qualitative Color Brewer palettes have different lengths, and the default behavior of color_palette() is to give you the full list: sns.color_palette(\"Paired\")", "prev_chunk_id": "chunk_133", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_135", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Sequential color palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Sequential color palettes#", "content": "Sequential color palettes# The second major class of color palettes is called “sequential”. This kind of mapping is appropriate when data range from relatively low or uninteresting values to relatively high or interesting values (or vice versa). As we saw above, the primary dimension of variation in a sequential palette is luminance. Some seaborn functions will default to a sequential palette when you are mapping numeric data. (For historical reasons, both categorical and numeric mappings are specified with the hue parameter in functions like relplot() or displot(), even though numeric mappings use color palettes with relatively little hue variation).", "prev_chunk_id": "chunk_134", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_136", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Perceptually uniform palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Perceptually uniform palettes#", "content": "Perceptually uniform palettes# Because they are intended to represent numeric values, the best sequential palettes will be perceptually uniform, meaning that the relative discriminability of two colors is proportional to the difference between the corresponding data values. Seaborn includes four perceptually uniform sequential colormaps: \"rocket\", \"mako\", \"flare\", and \"crest\". The first two have a very wide luminance range and are well suited for applications such as heatmaps, where colors fill the space they are plotted into: sns.color_palette(\"rocket\", as_cmap=True) sns.color_palette(\"mako\", as_cmap=True) Because the extreme values of these colormaps approach white, they are not well-suited for coloring elements such as lines or points: it will be difficult to discriminate important values against a white or gray background. The “flare” and “crest” colormaps are a better choice for such plots. They have a more restricted range of luminance variations, which they compensate for with a slightly more pronounced variation in hue. The default direction of the luminance ramp is also reversed, so that smaller values have lighter colors: sns.color_palette(\"flare\", as_cmap=True) sns.color_palette(\"crest\", as_cmap=True) It is also possible to use the perceptually uniform colormaps provided by matplotlib, such as \"magma\" and \"viridis\": sns.color_palette(\"magma\", as_cmap=True) sns.color_palette(\"viridis\", as_cmap=True) As with the convention in matplotlib, every continuous colormap has a reversed version, which has the suffix \"_r\": sns.color_palette(\"rocket_r\", as_cmap=True)", "prev_chunk_id": "chunk_135", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_137", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Discrete vs. continuous mapping#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Discrete vs. continuous mapping#", "content": "Discrete vs. continuous mapping# One thing to be aware of is that seaborn can generate discrete values from sequential colormaps and, when doing so, it will not use the most extreme values. Compare the discrete version of \"rocket\" against the continuous version shown above: sns.color_palette(\"rocket\") Internally, seaborn uses the discrete version for categorical data and the continuous version when in numeric mapping mode. Discrete sequential colormaps can be well-suited for visualizing categorical data with an intrinsic ordering, especially if there is some hue variation.", "prev_chunk_id": "chunk_136", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_138", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Sequential “cubehelix” palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Sequential “cubehelix” palettes#", "content": "Sequential “cubehelix” palettes# The perceptually uniform colormaps are difficult to programmatically generate, because they are not based on the RGB color space. The cubehelix system offers an RGB-based compromise: it generates sequential palettes with a linear increase or decrease in brightness and some continuous variation in hue. While not perfectly perceptually uniform, the resulting colormaps have many good properties. Importantly, many aspects of the design process are parameterizable. Matplotlib has the default cubehelix version built into it: sns.color_palette(\"cubehelix\", as_cmap=True) The default palette returned by the seaborn cubehelix_palette() function is a bit different from the matplotlib default in that it does not rotate as far around the hue wheel or cover as wide a range of intensities. It also reverses the luminance ramp: sns.cubehelix_palette(as_cmap=True) Other arguments to cubehelix_palette() control how the palette looks. The two main things you’ll change are the start (a value between 0 and 3) and rot, or number of rotations (an arbitrary value, but usually between -1 and 1) sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True) The more you rotate, the more hue variation you will see: sns.cubehelix_palette(start=.5, rot=-.75, as_cmap=True) You can control both how dark and light the endpoints are and their order: sns.cubehelix_palette(start=2, rot=0, dark=0, light=.95, reverse=True, as_cmap=True) The color_palette() accepts a string code, starting with \"ch:\", for generating an arbitrary cubehelix palette. You can passs the names of parameters in the string: sns.color_palette(\"ch:start=.2,rot=-.3\", as_cmap=True) And for compactness, each parameter can be specified with its first letter: sns.color_palette(\"ch:s=-.2,r=.6\", as_cmap=True)", "prev_chunk_id": "chunk_137", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_139", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Custom sequential palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Custom sequential palettes#", "content": "Custom sequential palettes# For a simpler interface to custom sequential palettes, you can use light_palette() or dark_palette(), which are both seeded with a single color and produce a palette that ramps either from light or dark desaturated values to that color: sns.light_palette(\"seagreen\", as_cmap=True) sns.dark_palette(\"#69d\", reverse=True, as_cmap=True) As with cubehelix palettes, you can also specify light or dark palettes through color_palette() or anywhere palette is accepted: sns.color_palette(\"light:b\", as_cmap=True) Reverse the colormap by adding \"_r\": sns.color_palette(\"dark:salmon_r\", as_cmap=True)", "prev_chunk_id": "chunk_138", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_140", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Sequential Color Brewer palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Sequential Color Brewer palettes#", "content": "Sequential Color Brewer palettes# The Color Brewer library also has some good options for sequential palettes. They include palettes with one primary hue: sns.color_palette(\"Blues\", as_cmap=True) Along with multi-hue options: sns.color_palette(\"YlOrBr\", as_cmap=True)", "prev_chunk_id": "chunk_139", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_141", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Diverging color palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Diverging color palettes#", "content": "Diverging color palettes# The third class of color palettes is called “diverging”. These are used for data where both large low and high values are interesting and span a midpoint value (often 0) that should be de-emphasized. The rules for choosing good diverging palettes are similar to good sequential palettes, except now there should be two dominant hues in the colormap, one at (or near) each pole. It’s also important that the starting values are of similar brightness and saturation.", "prev_chunk_id": "chunk_140", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_142", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Perceptually uniform diverging palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Perceptually uniform diverging palettes#", "content": "Perceptually uniform diverging palettes# Seaborn includes two perceptually uniform diverging palettes: \"vlag\" and \"icefire\". They both use blue and red at their poles, which many intuitively processes as “cold” and “hot”: sns.color_palette(\"vlag\", as_cmap=True) sns.color_palette(\"icefire\", as_cmap=True)", "prev_chunk_id": "chunk_141", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_143", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Custom diverging palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Custom diverging palettes#", "content": "Custom diverging palettes# You can also use the seaborn function diverging_palette() to create a custom colormap for diverging data. This function makes diverging palettes using the husl color system. You pass it two hues (in degrees) and, optionally, the lightness and saturation values for the extremes. Using husl means that the extreme values, and the resulting ramps to the midpoint, while not perfectly perceptually uniform, will be well-balanced: sns.diverging_palette(220, 20, as_cmap=True) This is convenient when you want to stray from the boring confines of cold-hot approaches: sns.diverging_palette(145, 300, s=60, as_cmap=True) It’s also possible to make a palette where the midpoint is dark rather than light: sns.diverging_palette(250, 30, l=65, center=\"dark\", as_cmap=True) It’s important to emphasize here that using red and green, while intuitive, should be avoided.", "prev_chunk_id": "chunk_142", "next_chunk_id": null, "type": "section"},
{"chunk_id": "chunk_144", "url": "https://seaborn.pydata.org/tutorial/color_palettes.html", "title": "Other diverging palettes#", "page_title": "Choosing color palettes — seaborn 0.13.2 documentation", "breadcrumbs": "Other diverging palettes#", "content": "Other diverging palettes# There are a few other good diverging palettes built into matplotlib, including Color Brewer palettes: sns.color_palette(\"Spectral\", as_cmap=True) And the coolwarm palette, which has less contrast between the middle values and the extremes: sns.color_palette(\"coolwarm\", as_cmap=True) As you can see, there are many options for using color in your visualizations. Seaborn tries both to use good defaults and to offer a lot of flexibility. This discussion is only the beginning, and there are a number of good resources for learning more about techniques for using color in visualizations. One great example is this series of blog posts from the NASA Earth Observatory. The matplotlib docs also have a nice tutorial that illustrates some of the perceptual properties of their colormaps.", "prev_chunk_id": "chunk_143", "next_chunk_id": null, "type": "section"}
]